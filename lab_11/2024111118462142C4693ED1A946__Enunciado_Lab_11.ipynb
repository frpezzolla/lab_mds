{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PyPTffTLug7i"
   },
   "source": [
    "# **Laboratorio 11: LLM y Agentes Aut贸nomos **\n",
    "\n",
    "MDS7202: Laboratorio de Programaci贸n Cient铆fica para Ciencia de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5pbWVyntzbvL"
   },
   "source": [
    "### **Cuerpo Docente:**\n",
    "\n",
    "- Profesores: Ignacio Meza, Sebasti谩n Tinoco\n",
    "- Auxiliar: Eduardo Moya\n",
    "- Ayudantes: Nicol谩s Ojeda, Melanie Pe帽a, Valentina Rojas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dy6ikgVYzghB"
   },
   "source": [
    "### **Equipo: SUPER IMPORTANTE - notebooks sin nombre no ser谩n revisados**\n",
    "\n",
    "- Nombre de alumno 1:\n",
    "- Nombre de alumno 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iMJ-owchzjFf"
   },
   "source": [
    "### **Link de repositorio de GitHub:** [Insertar Repositorio](https://github.com/...../)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WUuwsXrKzmkK"
   },
   "source": [
    "## **Temas a tratar**\n",
    "\n",
    "- Reinforcement Learning\n",
    "- Large Language Models\n",
    "\n",
    "## **Reglas:**\n",
    "\n",
    "- **Grupos de 2 personas**\n",
    "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser谩n respondidos por este medio.\n",
    "- Prohibidas las copias.\n",
    "- Pueden usar cualquer matrial del curso que estimen conveniente.\n",
    "\n",
    "### **Objetivos principales del laboratorio**\n",
    "\n",
    "- Resoluci贸n de problemas secuenciales usando Reinforcement Learning\n",
    "- Habilitar un Chatbot para entregar respuestas 煤tiles usando Large Language Models.\n",
    "\n",
    "El laboratorio deber谩 ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al m谩ximo las funciones optimizadas que nos entrega `pandas`, las cuales vale mencionar, son bastante m谩s eficientes que los iteradores nativos sobre DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0hmHHQ9BuyAG"
   },
   "source": [
    "## **1. Reinforcement Learning (2.0 puntos)**\n",
    "\n",
    "En esta secci贸n van a usar m茅todos de RL para resolver dos problemas interesantes: `Blackjack` y `LunarLander`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gOcejYb6uzOO"
   },
   "outputs": [],
   "source": [
    "!pip install -qqq gymnasium stable_baselines3\n",
    "!pip install -qqq swig\n",
    "!pip install -qqq gymnasium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qBPet_Mq8dX9"
   },
   "source": [
    "### **1.1 Blackjack (1.0 puntos)**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://www.recreoviral.com/wp-content/uploads/2016/08/s3.amazonaws.com-Math.gif\"\n",
    "\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "La idea de esta subsecci贸n es que puedan implementar m茅todos de RL y as铆 generar una estrategia para jugar el cl谩sico juego Blackjack y de paso puedan ~~hacerse millonarios~~ aprender a resolver problemas mediante RL.\n",
    "\n",
    "Comencemos primero preparando el ambiente. El siguiente bloque de c贸digo transforma las observaciones del ambiente a `np.array`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "LpZ8bBKk9ZlU"
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium.spaces import MultiDiscrete\n",
    "import numpy as np\n",
    "\n",
    "class FlattenObservation(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super(FlattenObservation, self).__init__(env)\n",
    "        self.observation_space = MultiDiscrete(np.array([32, 11, 2]))\n",
    "\n",
    "    def observation(self, observation):\n",
    "        return np.array(observation).flatten()\n",
    "\n",
    "# Create and wrap the environment\n",
    "env = gym.make(\"Blackjack-v1\")\n",
    "env = FlattenObservation(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZJ6J1_-Y9nHO"
   },
   "source": [
    "#### **1.1.1 Descripci贸n de MDP (0.2 puntos)**\n",
    "\n",
    "Entregue una breve descripci贸n sobre el ambiente [Blackjack](https://gymnasium.farama.org/environments/toy_text/blackjack/) y su formulaci贸n en MDP, distinguiendo de forma clara y concisa los estados, acciones y recompensas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El ambiente de Blackjack en Gymnasium es una simulaci贸n del cl谩sico juego de cartas. Su formulaci贸n en MDP (Proceso de Decisi贸n de Markov) es la siguiente:\n",
    "\n",
    "- **Estados**: Un estado est谩 representado por una tupla `(suma_agente, carta_visible_dealer, agente_tiene_as)`, donde:\n",
    "    - `suma_agente`: Suma de las cartas del agente (valor entre 0 y 31).\n",
    "    - `carta_visible_dealer`: Valor de la carta visible del dealer (valor entre 1 y 10, donde 1 representa un As).\n",
    "    - `agente_tiene_as`: Indica si el agente tiene un As que puede contar como 11 sin pasarse de 21 (valor 0 o 1).\n",
    "\n",
    "- **Acciones**: Las acciones posibles son:\n",
    "    - `0`: Pedir carta (Hit).\n",
    "    - `1`: Plantarse (Stick).\n",
    "\n",
    "- **Recompensas**:\n",
    "    - `+1`: Si el agente gana.\n",
    "    - `0`: Si hay un empate.\n",
    "    - `-1`: Si el agente pierde.\n",
    "\n",
    "El objetivo del agente es maximizar la recompensa acumulada a lo largo de los episodios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pmcX6bRC9agQ"
   },
   "source": [
    "#### **1.1.2 Generando un Baseline (0.2 puntos)**\n",
    "\n",
    "Simule un escenario en donde se escojan acciones aleatorias. Repita esta simulaci贸n 5000 veces y reporte el promedio y desviaci贸n de las recompensas. 驴C贸mo calificar铆a el performance de esta pol铆tica? 驴C贸mo podr铆a interpretar las recompensas obtenidas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9p2PrLLR9yju"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promedio de las recompensas: -0.4014\n",
      "Desviaci贸n est谩ndar de las recompensas: 0.8912227779853924\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "env = gym.make(\"Blackjack-v1\")\n",
    "\n",
    "num_episodes = 5000\n",
    "rewards = []\n",
    "\n",
    "for _ in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    \n",
    "    while not done:\n",
    "        action = env.action_space.sample()\n",
    "        state, reward, done, _, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "    \n",
    "    rewards.append(total_reward)\n",
    "\n",
    "mean_reward = np.mean(rewards)\n",
    "std_reward = np.std(rewards)\n",
    "\n",
    "print(f\"Promedio de las recompensas: {mean_reward}\")\n",
    "print(f\"Desviaci贸n est谩ndar de las recompensas: {std_reward}\")\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(rewards, bins=20, edgecolor='black')\n",
    "plt.title('Distribuci贸n de Recompensas')\n",
    "plt.xlabel('Recompensa')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El performance de la pol铆tica de acciones aleatorias en el ambiente de Blackjack es bastante pobre. Esto se refleja en el promedio de recompensas obtenido, que es de -0.3926, con una desviaci贸n est谩ndar de 0.8960. (aunque siempre cambia al hacer click pero no var铆a tanto la proporci贸n)\n",
    "\n",
    "### Interpretaci贸n de las Recompensas Obtenidas\n",
    "\n",
    "- **Promedio de Recompensas**: Un promedio negativo indica que, en general, el agente pierde m谩s juegos de los que gana. Esto es esperable dado que las acciones se seleccionan de manera aleatoria, sin ninguna estrategia que maximice las recompensas.\n",
    "- **Desviaci贸n Est谩ndar**: La desviaci贸n est谩ndar de 0.8960 sugiere que hay una variabilidad considerable en las recompensas obtenidas. Esto significa que, aunque el agente pierde en promedio, hay episodios en los que puede ganar o empatar, pero estos son menos frecuentes.\n",
    "\n",
    "La pol铆tica de acciones aleatorias no es efectiva para el ambiente de Blackjack, ya que no sigue ninguna estrategia que le permita maximizar sus recompensas. Para mejorar el performance, ser铆a necesario implementar una pol铆tica m谩s informada o entrenar un modelo de aprendizaje por refuerzo que aprenda a tomar decisiones 贸ptimas en este ambiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LEO_dY4x_SJu"
   },
   "source": [
    "#### **1.1.3 Entrenamiento de modelo (0.2 puntos)**\n",
    "\n",
    "A partir del siguiente [enlace](https://stable-baselines3.readthedocs.io/en/master/guide/algos.html), escoja un modelo de `stable_baselines3` y entrenelo para resolver el ambiente `Blackjack`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m9JsFA1wGmnH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.31     |\n",
      "|    ep_rew_mean     | -0.46    |\n",
      "| time/              |          |\n",
      "|    fps             | 419      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.3         |\n",
      "|    ep_rew_mean          | -0.24       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 331         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017976332 |\n",
      "|    clip_fraction        | 0.336       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.678      |\n",
      "|    explained_variance   | -0.132      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.249       |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0512     |\n",
      "|    value_loss           | 0.751       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.28       |\n",
      "|    ep_rew_mean          | -0.34      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 321        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 19         |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02092089 |\n",
      "|    clip_fraction        | 0.304      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.627     |\n",
      "|    explained_variance   | 0.082      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.315      |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.0487    |\n",
      "|    value_loss           | 0.739      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.2        |\n",
      "|    ep_rew_mean          | -0.25      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 313        |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 26         |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03204823 |\n",
      "|    clip_fraction        | 0.258      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.544     |\n",
      "|    explained_variance   | 0.112      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.351      |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | -0.0398    |\n",
      "|    value_loss           | 0.731      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.21        |\n",
      "|    ep_rew_mean          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016903449 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.478      |\n",
      "|    explained_variance   | 0.162       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.373       |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0198     |\n",
      "|    value_loss           | 0.74        |\n",
      "-----------------------------------------\n",
      "Recompensa obtenida: [1.]\n",
      "Recompensa obtenida: [-1.]\n",
      "Recompensa obtenida: [1.]\n",
      "Recompensa obtenida: [-1.]\n",
      "Recompensa obtenida: [-1.]\n",
      "Recompensa obtenida: [0.]\n",
      "Recompensa obtenida: [-1.]\n",
      "Recompensa obtenida: [1.]\n",
      "Recompensa obtenida: [0.]\n",
      "Recompensa obtenida: [0.]\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "class FlattenObservation(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=0, high=1, shape=(32 + 10 + 1,), dtype=np.float32 \n",
    "        )\n",
    "\n",
    "    def observation(self, observation):\n",
    "        return np.concatenate([\n",
    "            np.eye(32)[observation[0] - 4], \n",
    "            np.eye(10)[observation[1] - 1], \n",
    "            np.array([observation[2]])  \n",
    "        ]).astype(np.float32)\n",
    "\n",
    "env = gym.make(\"Blackjack-v1\")\n",
    "env = FlattenObservation(env)\n",
    "env = make_vec_env(lambda: env, n_envs=1)\n",
    "\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=10000)\n",
    "\n",
    "model.save(\"ppo_blackjack_model\")\n",
    "\n",
    "obs = env.reset()\n",
    "for _ in range(10): \n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    print(f\"Recompensa obtenida: {rewards}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-bpdb8wZID1"
   },
   "source": [
    "#### **1.1.4 Evaluaci贸n de modelo (0.2 puntos)**\n",
    "\n",
    "Repita el ejercicio 1.1.2 pero utilizando el modelo entrenado. 驴C贸mo es el performance de su agente? 驴Es mejor o peor que el escenario baseline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5-d7d8GFf7F6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recompensa media: -0.0992\n",
      "Desviaci贸n est谩ndar de la recompensa: 0.9604995366995239\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=5000)\n",
    "\n",
    "print(f\"Recompensa media: {mean_reward}\")\n",
    "print(f\"Desviaci贸n est谩ndar de la recompensa: {std_reward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El performance del agente entrenado utilizando el modelo PPO es significativamente mejor que el escenario baseline de acciones aleatorias. Esto se refleja en la recompensa media obtenida, que es de -0.0716, con una desviaci贸n est谩ndar de 0.9650. (Que cambia cada vez que se ejecuta el c贸digo)\n",
    "\n",
    "### Comparaci贸n con el Baseline\n",
    "\n",
    "- **Promedio de Recompensas**: El promedio de recompensas del agente entrenado es mucho m谩s cercano a cero en comparaci贸n con el promedio negativo del baseline (-0.3926). Esto indica que el agente entrenado pierde menos juegos y tiene un mejor desempe帽o general.\n",
    "- **Desviaci贸n Est谩ndar**: La desviaci贸n est谩ndar de las recompensas del agente entrenado es ligeramente mayor que la del baseline (0.9650 vs. 0.8960). Esto sugiere que hay una mayor variabilidad en las recompensas obtenidas, lo cual es esperable dado que el agente est谩 tomando decisiones m谩s informadas y, por lo tanto, puede ganar m谩s juegos en algunos episodios.\n",
    "\n",
    "En resumen, el agente entrenado con PPO muestra un mejor performance en comparaci贸n con la pol铆tica de acciones aleatorias, lo que demuestra la efectividad del modelo de RL en aprender una estrategia para el juego de Blackjack."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RO-EsAaPAYEm"
   },
   "source": [
    "#### **1.1.5 Estudio de acciones (0.2 puntos)**\n",
    "\n",
    "Genere una funci贸n que reciba un estado y retorne la accion del agente. Luego, use esta funci贸n para entregar la acci贸n escogida frente a los siguientes escenarios:\n",
    "\n",
    "- Suma de cartas del agente es 6, dealer muestra un 7, agente no tiene tiene un as\n",
    "- Suma de cartas del agente es 19, dealer muestra un 3, agente tiene tiene un as\n",
    "\n",
    "驴Son coherentes sus acciones con las reglas del juego?\n",
    "\n",
    "Hint: 驴A que clase de python pertenecen los estados? Pruebe a usar el m茅todo `.reset` para saberlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fh8XlGyzwtRp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para el estado (6, 7, 0), la acci贸n escogida es: 0\n",
      "Para el estado (19, 3, 1), la acci贸n escogida es: 0\n"
     ]
    }
   ],
   "source": [
    "def get_action(state):\n",
    "    \"\"\"\n",
    "    Funci贸n que recibe un estado y retorna la acci贸n del agente.\n",
    "    \n",
    "    Par谩metros:\n",
    "    state (tuple): El estado del ambiente (suma_agente, carta_visible_dealer, agente_tiene_as)\n",
    "    \n",
    "    Retorna:\n",
    "    int: La acci贸n escogida por el agente\n",
    "    \"\"\"\n",
    "\n",
    "    observation = np.concatenate([\n",
    "        np.eye(32)[state[0] - 4], \n",
    "        np.eye(10)[state[1] - 1], \n",
    "        np.array([state[2]]) \n",
    "    ]).astype(np.float32).reshape(1, -1)\n",
    "    \n",
    "    action, _ = model.predict(observation, deterministic=True)\n",
    "    return action[0]\n",
    "\n",
    "scenarios = [(6, 7, 0), (19, 3, 1)]\n",
    "\n",
    "for scenario in scenarios:\n",
    "    action = get_action(scenario)\n",
    "    print(f\"Para el estado {scenario}, la acci贸n escogida es: {action}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las acciones escogidas por el agente entrenado son coherentes con las reglas del juego de Blackjack. A continuaci贸n se detallan las acciones para los escenarios proporcionados:\n",
    "\n",
    "- **Escenario 1**: Suma de cartas del agente es 6, dealer muestra un 7, agente no tiene un as.\n",
    "    - **Acci贸n escogida**: 0 (Pedir carta)\n",
    "    - **Coherencia**: Es coherente, ya que con una suma de 6, es muy probable que el agente necesite pedir una carta para acercarse a 21.\n",
    "\n",
    "- **Escenario 2**: Suma de cartas del agente es 19, dealer muestra un 3, agente tiene un as.\n",
    "    - **Acci贸n escogida**: 0 (Pedir carta)\n",
    "    - **Coherencia**: No es coherente, ya que con una suma de 19, la estrategia b谩sica sugiere plantarse, especialmente considerando que el dealer muestra una carta baja (3).\n",
    "\n",
    "En el primer caso, la acci贸n del agente es coherente con las estrategias b谩sicas del juego de Blackjack. Sin embargo, en el segundo caso, la acci贸n no es coherente con las estrategias b谩sicas del juego.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SEqCTqqroh03"
   },
   "source": [
    "### **1.2 LunarLander**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://i.redd.it/097t6tk29zf51.jpg\"\n",
    "\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "Similar a la secci贸n 2.1, en esta secci贸n usted se encargar谩 de implementar una gente de RL que pueda resolver el ambiente `LunarLander`.\n",
    "\n",
    "Comencemos preparando el ambiente:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "nvQUyuZ_FtZ4"
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "env = gym.make(\"LunarLander-v2\", render_mode = \"rgb_array\", continuous = True) # notar el par谩metro continuous = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El par谩metro continuous = True generalmente se utiliza en el contexto de simulaciones o procesos que requieren una ejecuci贸n continua. Dependiendo del entorno o la biblioteca que est茅s utilizando, este par谩metro puede tener diferentes implicancias. Aqu铆 hay algunas posibles implicancias generales:\n",
    "\n",
    "Ejecuci贸n Ininterrumpida: El proceso o simulaci贸n se ejecutar谩 de manera continua sin pausas o interrupciones hasta que se cumpla una condici贸n espec铆fica o se detenga manualmente.\n",
    "\n",
    "Actualizaci贸n Constante: Si se trata de una simulaci贸n gr谩fica o un entorno interactivo, el entorno se actualizar谩 constantemente para reflejar los cambios en tiempo real.\n",
    "\n",
    "Consumo de Recursos: La ejecuci贸n continua puede implicar un mayor consumo de recursos del sistema (CPU, memoria), ya que el proceso no se detiene y sigue ejecut谩ndose.\n",
    "\n",
    "Manejo de Eventos: En algunos entornos, continuous = True puede implicar que el sistema maneje eventos de manera continua, como entradas del usuario, cambios en el entorno, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FBU4lGX3wpN6"
   },
   "source": [
    "Noten que se especifica el par谩metro `continuous = True`. 驴Que implicancias tiene esto sobre el ambiente?\n",
    "\n",
    "Adem谩s, se le facilita la funci贸n `export_gif` para el ejercicio 2.2.4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "bRiWpSo9yfr9"
   },
   "outputs": [],
   "source": [
    "import imageio\n",
    "import numpy as np\n",
    "\n",
    "def export_gif(model, n = 5):\n",
    "  '''\n",
    "  funci贸n que exporta a gif el comportamiento del agente en n episodios\n",
    "  '''\n",
    "  images = []\n",
    "  for episode in range(n):\n",
    "    obs = model.env.reset()\n",
    "    img = model.env.render()\n",
    "    done = False\n",
    "    while not done:\n",
    "      images.append(img)\n",
    "      action, _ = model.predict(obs)\n",
    "      obs, reward, done, info = model.env.step(action)\n",
    "      img = model.env.render(mode=\"rgb_array\")\n",
    "\n",
    "  imageio.mimsave(\"agent_performance.gif\", [np.array(img) for i, img in enumerate(images) if i%2 == 0], fps=29)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sk5VJVppXh3N"
   },
   "source": [
    "#### **1.2.1 Descripci贸n de MDP (0.2 puntos)**\n",
    "\n",
    "Entregue una breve descripci贸n sobre el ambiente [LunarLander](https://gymnasium.farama.org/environments/box2d/lunar_lander/) y su formulaci贸n en MDP, distinguiendo de forma clara y concisa los estados, acciones y recompensas. 驴Como se distinguen las acciones de este ambiente en comparaci贸n a `Blackjack`?\n",
    "\n",
    "Nota: recuerde que se especific贸 el par谩metro `continuous = True`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yb-u9LUE8O9a"
   },
   "source": [
    "El ambiente de LunarLander en Gymnasium es una simulaci贸n del aterrizaje de un m贸dulo lunar. Su formulaci贸n en MDP (Proceso de Decisi贸n de Markov) es la siguiente:\n",
    "\n",
    "- **Estados**: Un estado est谩 representado por un vector continuo de 8 dimensiones que incluye:\n",
    "    - `x` y `y`: Posici贸n del m贸dulo.\n",
    "    - `vx` y `vy`: Velocidades del m贸dulo en los ejes x e y.\n",
    "    - `胃` y `v胃`: ngulo y velocidad angular del m贸dulo.\n",
    "    - `left_leg_contact` y `right_leg_contact`: Indicadores binarios de si las patas izquierda y derecha del m贸dulo est谩n en contacto con el suelo.\n",
    "\n",
    "- **Acciones**: Las acciones posibles son:\n",
    "    - `0`: No hacer nada.\n",
    "    - `1`: Encender el motor principal.\n",
    "    - `2`: Encender el motor izquierdo.\n",
    "    - `3`: Encender el motor derecho.\n",
    "\n",
    "- **Recompensas**:\n",
    "    - La recompensa se basa en la proximidad al objetivo de aterrizaje, la velocidad, el uso de combustible y el contacto con el suelo.\n",
    "    - Se otorgan recompensas adicionales por aterrizar suavemente y penalizaciones por colisiones.\n",
    "\n",
    "El objetivo del agente es maximizar la recompensa acumulada a lo largo de los episodios.\n",
    "\n",
    "### Comparaci贸n de Acciones con Blackjack\n",
    "\n",
    "A diferencia del ambiente de Blackjack, donde las acciones son discretas y limitadas a \"Pedir carta\" o \"Plantarse\", en LunarLander las acciones son m谩s variadas y continuas, lo que permite un control m谩s fino del agente en un entorno din谩mico y f铆sico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YChodtNQwzG2"
   },
   "source": [
    "#### **1.2.2 Generando un Baseline (0.2 puntos)**\n",
    "\n",
    "Simule un escenario en donde se escojan acciones aleatorias. Repita esta simulaci贸n 10 veces y reporte el promedio y desviaci贸n de las recompensas. 驴C贸mo calificar铆a el performance de esta pol铆tica?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5bwc3A0GX7a8",
    "vscode": {
     "languageId": "groovy"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promedio de las recompensas: -149.31400185474973\n",
      "Desviaci贸n est谩ndar de las recompensas: 91.36155146102415\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABAb0lEQVR4nO3deVwV9f7H8fdB8QAiuLG4oJKa+0KYiru5oFlpi5XVdc3qppnh1cJK065RltttcamrtllupZUr4VYuuUHlkrljKriUkKig8v390Y9zPQEKiBwYX8/H4zwezne+M/OZL0d8O/Odc2zGGCMAAACLcHN1AQAAAPmJcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMg11JTU/Xaa69pxYoVri4FADIh3ABX8corr8hmsxXIsdq1a6d27do5ltesWSObzaYFCxYUyPGvZLPZ9Morr2S7PiIiQp9++qmaNWtWIPX07dtX1apVK5BjASj6CDe4acyePVs2m83x8vDwUMWKFRUeHq7//Oc/+vPPP/PlOMeOHdMrr7yiuLi4fNlfYTNv3jwtWrRIy5YtU+nSpV1dTp5khNaMl7u7u6pVq6YhQ4bozJkzri4PwHUq7uoCgII2duxYBQcH6+LFi0pISNCaNWs0dOhQTZw4UV999ZUaNmzo6PvSSy/phRdeyNX+jx07pjFjxqhatWpq3LhxjrdbuXJlro5zI50/f17Fi2f+9WCM0W+//aZly5apSpUqLqgsf02dOlXe3t5KSUlRTEyM3n77bW3fvl3ff/+9q0sDcB0IN7jpdO3aVU2aNHEsR0ZGatWqVbrrrrt0zz33aPfu3fL09JQkFS9ePMt/5PPTuXPn5OXlpRIlStzQ4+SGh4dHlu02m00REREFXM2N88ADD6h8+fKSpCeffFIPP/yw5s6dq82bN6tp06Yurg5AXnFbCpB0xx136OWXX9bhw4f1ySefONqzmnMTHR2tVq1aqXTp0vL29latWrU0cuRISX/Nk7n99tslSf369XPc9pg9e7akv+bV1K9fX9u2bVObNm3k5eXl2Pbvc24yXL58WSNHjlRgYKBKliype+65R0eOHHHqU61aNfXt2zfTtlnt88KFC3rllVd06623ysPDQxUqVNB9992n/fv3O/pkNecmNjZWXbt2lY+Pj7y9vdWhQwdt2rTJqU/Grb/169crIiJCfn5+KlmypO69916dPHkyU31ZWbRokerXry8PDw/Vr19fX375ZZb90tPTNXnyZNWrV08eHh4KCAjQk08+qT/++CNHx8lK69atJclpLCTphx9+UJcuXeTr6ysvLy+1bdtW69evz7T90aNHNWDAAFWsWFF2u13BwcH65z//qbS0NEefAwcOqGfPnipbtqy8vLzUvHlzLVmyxGk/GfOt5s2bpzFjxqhSpUoqVaqUHnjgASUlJSk1NVVDhw6Vv7+/vL291a9fP6Wmpjrtw2azafDgwfr0009Vq1YteXh4KDQ0VOvWrcuy7v79+ysgIEB2u1316tXTzJkzs61p3Lhxqly5sjw8PNShQwft27fPqe/evXt1//33KzAwUB4eHqpcubIefvhhJSUlOfrMmjVLd9xxh/z9/WW321W3bl1NnTo1U21bt25VeHi4ypcvL09PTwUHB6t///6Z+gFX4soN8P/+8Y9/aOTIkVq5cqUGDhyYZZ+dO3fqrrvuUsOGDTV27FjZ7Xbt27fP8Q9dnTp1NHbsWI0aNUpPPPGE4x/LFi1aOPZx+vRpde3aVQ8//LAee+wxBQQEXLWucePGyWaz6fnnn9eJEyc0efJkdezYUXFxcY4rTDl1+fJl3XXXXYqJidHDDz+sZ599Vn/++aeio6O1Y8cOVa9ePdvzbt26tXx8fDRixAi5u7tr+vTpateundauXZtpYvEzzzyjMmXKaPTo0Tp06JAmT56swYMHa+7cuVetb+XKlbr//vtVt25dRUVF6fTp0+rXr58qV66cqe+TTz6p2bNnq1+/fhoyZIgOHjyod955R7GxsVq/fr3c3d1zNTaSdOjQIUlSmTJlHG2rVq1S165dFRoaqtGjR8vNzc3xD/N3333nuMJz7NgxNW3aVGfOnNETTzyh2rVr6+jRo1qwYIHOnTunEiVKKDExUS1atNC5c+c0ZMgQlStXTh9++KHuueceLViwQPfee69TPVFRUfL09NQLL7ygffv26e2335a7u7vc3Nz0xx9/6JVXXtGmTZs0e/ZsBQcHa9SoUU7br127VnPnztWQIUNkt9v13nvvqUuXLtq8ebPq168vSUpMTFTz5s0dYcjPz0/Lli3TgAEDlJycrKFDhzrt8/XXX5ebm5v+9a9/KSkpSePHj9ejjz6qH374QZKUlpam8PBwpaam6plnnlFgYKCOHj2qb775RmfOnJGvr6+kv24J1qtXT/fcc4+KFy+ur7/+Wk8//bTS09M1aNAgSdKJEyfUuXNn+fn56YUXXlDp0qV16NAhffHFF7n+2eImY4CbxKxZs4wks2XLlmz7+Pr6mpCQEMfy6NGjzZV/TSZNmmQkmZMnT2a7jy1bthhJZtasWZnWtW3b1kgy06ZNy3Jd27ZtHcurV682kkylSpVMcnKyo33evHlGkpkyZYqjrWrVqqZPnz7X3OfMmTONJDNx4sRMfdPT0x1/lmRGjx7tWO7Ro4cpUaKE2b9/v6Pt2LFjplSpUqZNmzaOtowx7tixo9P+nnvuOVOsWDFz5syZTMe9UuPGjU2FChWc+q1cudJIMlWrVnW0fffdd0aS+fTTT522X758eZbtf5fxc92zZ485efKkOXTokJk5c6bx9PQ0fn5+JiUlxTEmNWvWNOHh4U7nc+7cORMcHGw6derkaOvdu7dxc3PL8v2Vse3QoUONJPPdd9851v35558mODjYVKtWzVy+fNkY87+fff369U1aWpqjb69evYzNZjNdu3Z12n9YWJjT+Bjz189Qktm6dauj7fDhw8bDw8Pce++9jrYBAwaYChUqmFOnTjlt//DDDxtfX19z7tw5p5rq1KljUlNTHf2mTJliJJmff/7ZGGNMbGyskWTmz5+faRyulLHfK4WHh5tbbrnFsfzll19e8+8skBVuSwFX8Pb2vupTUxlPBy1evFjp6el5Oobdble/fv1y3L93794qVaqUY/mBBx5QhQoVtHTp0lwfe+HChSpfvryeeeaZTOuye+T98uXLWrlypXr06KFbbrnF0V6hQgU98sgj+v7775WcnOy0zRNPPOG0v9atW+vy5cs6fPhwtrUdP35ccXFx6tOnj+N/95LUqVMn1a1b16nv/Pnz5evrq06dOunUqVOOV2hoqLy9vbV69eqrD8T/q1Wrlvz8/FStWjX1799fNWrU0LJly+Tl5SVJiouL0969e/XII4/o9OnTjuOkpKSoQ4cOWrdundLT05Wenq5Fixbp7rvvdprPlSFjLJYuXaqmTZuqVatWjnXe3t564okndOjQIe3atctpu969eztdgWrWrJmMMZluyzRr1kxHjhzRpUuXnNrDwsIUGhrqWK5SpYq6d++uFStW6PLlyzLGaOHChbr77rtljHEay/DwcCUlJWn79u1O++zXr5/T/LCMq5MHDhyQJMfPbsWKFTp37ly2Y3/lVcekpCSdOnVKbdu21YEDBxy3rzL+vn3zzTe6ePFitvsC/o5wA1zh7NmzTkHi7x566CG1bNlSjz/+uAICAvTwww9r3rx5uQo6lSpVytXk4Zo1azot22w21ahRw3ELJTf279+vWrVq5WqS9MmTJ3Xu3DnVqlUr07o6deooPT090xygvz9JlXGb52rzYTKCz9/PV1KmY+/du1dJSUny9/eXn5+f0+vs2bM6ceJEjs5t4cKFio6O1pw5c9S8eXOdOHHC6R/dvXv3SpL69OmT6TgffPCBUlNTlZSUpJMnTyo5Odlxq+dq55jdOF45Bhn+Po4ZwSEoKChTe3p6utOcFinrsbz11lt17tw5nTx5UidPntSZM2c0Y8aMTOeXEcD/PpbX+tkGBwcrIiJCH3zwgcqXL6/w8HC9++67mWpbv369OnbsqJIlS6p06dLy8/NzzD/L6Nu2bVvdf//9GjNmjMqXL6/u3btr1qxZmeYXAX/HnBvg//32229KSkpSjRo1su3j6empdevWafXq1VqyZImWL1+uuXPn6o477tDKlStVrFixax4nt/NkcuJqV11yUlN+y+6Yxph82X96err8/f316aefZrnez88vR/tp06aN42mpu+++Ww0aNNCjjz6qbdu2yc3NzRFa33zzzWwf6/f29tbvv/+e+5PIgezGMb/GN+P8HnvsMfXp0yfLPld+NEJOjz1hwgT17dtXixcv1sqVKzVkyBBFRUVp06ZNqly5svbv368OHTqodu3amjhxooKCglSiRAktXbpUkyZNctSV8SGWmzZt0tdff60VK1aof//+mjBhgjZt2iRvb+9cnS9uHoQb4P99/PHHkqTw8PCr9nNzc1OHDh3UoUMHTZw4Ua+99ppefPFFrV69Wh07dsz3TzTOuHqQwRijffv2Of2jU6ZMmSw/fO7w4cNOt5KqV6+uH374QRcvXszxhFs/Pz95eXlpz549mdb98ssvcnNzy3QlIS+qVq0qKfP5Ssp07OrVq+vbb79Vy5Yt8y0sent7a/To0erXr5/mzZunhx9+2DHB2sfHRx07dsx2Wz8/P/n4+GjHjh1XPUbVqlWzHceM9fkpq7H89ddf5eXl5QiApUqV0uXLl696fnnRoEEDNWjQQC+99JI2bNigli1batq0afr3v/+tr7/+Wqmpqfrqq6+crgRldzuxefPmat68ucaNG6c5c+bo0Ucf1eeff67HH388X2uGdXBbCtBfT8S8+uqrCg4O1qOPPpptv6z+h57xP/qMS+UlS5aUpHz7pNuPPvrIaR7QggULdPz4cXXt2tXRVr16dW3atMnpkeNvvvkm0+2i+++/X6dOndI777yT6TjZ/a+/WLFi6ty5sxYvXux0KywxMVFz5sxRq1at5OPjk9fTc6hQoYIaN26sDz/80OkWRnR0dKa5KA8++KAuX76sV199NdN+Ll26lOexf/TRR1W5cmW98cYbkqTQ0FBVr15db731ls6ePZupf8bj7W5uburRo4e+/vprbd26NVO/jLG98847tXnzZm3cuNGxLiUlRTNmzFC1atUyzS26Xhs3bnSaM3PkyBEtXrxYnTt3VrFixVSsWDHdf//9WrhwYZbBLKeP718pOTk509yfBg0ayM3NzfF3JOPqz5XvuaSkJM2aNctpuz/++CPT+/Lvf9+ArHDlBjedZcuW6ZdfftGlS5eUmJioVatWKTo6WlWrVtVXX32V7QfYSX99uvG6devUrVs3Va1aVSdOnNB7772nypUrOyaJVq9eXaVLl9a0adNUqlQplSxZUs2aNVNwcHCe6i1btqxatWqlfv36KTExUZMnT1aNGjWcHld//PHHtWDBAnXp0kUPPvig9u/fr08++STTo929e/fWRx99pIiICG3evFmtW7dWSkqKvv32Wz399NPq3r17ljX8+9//dny+z9NPP63ixYtr+vTpSk1N1fjx4/N0XlmJiopSt27d1KpVK/Xv31+///673n77bdWrV88pXLRt21ZPPvmkoqKiFBcXp86dO8vd3V179+7V/PnzNWXKFD3wwAO5Pr67u7ueffZZDR8+XMuXL1eXLl30wQcfqGvXrqpXr5769eunSpUq6ejRo1q9erV8fHz09ddfS5Jee+01rVy5Um3bttUTTzyhOnXq6Pjx45o/f76+//57lS5dWi+88II+++wzde3aVUOGDFHZsmX14Ycf6uDBg1q4cKHc3PL3/5v169dXeHi406PgkjRmzBhHn9dff12rV69Ws2bNNHDgQNWtW1e///67tm/frm+//TbXt9xWrVqlwYMHq2fPnrr11lt16dIlffzxx44gJUmdO3dWiRIldPfdd+vJJ5/U2bNn9f7778vf31/Hjx937OvDDz/Ue++9p3vvvVfVq1fXn3/+qffff18+Pj66884782GEYFkuekoLKHAZjylnvEqUKGECAwNNp06dzJQpU5wet87w90fBY2JiTPfu3U3FihVNiRIlTMWKFU2vXr3Mr7/+6rTd4sWLTd26dU3x4sWdHgtv27atqVevXpb1Zfco+GeffWYiIyONv7+/8fT0NN26dTOHDx/OtP2ECRNMpUqVjN1uNy1btjRbt27NtE9j/noE98UXXzTBwcHG3d3dBAYGmgceeMDpMW/97VFwY4zZvn27CQ8PN97e3sbLy8u0b9/ebNiwIcsx/vujuxnnsnr16izP/UoLFy40derUMXa73dStW9d88cUXpk+fPpkedTbGmBkzZpjQ0FDj6elpSpUqZRo0aGBGjBhhjh07dtVjZPxcs3qkPykpyfj6+jqNW2xsrLnvvvtMuXLljN1uN1WrVjUPPvigiYmJcdr28OHDpnfv3sbPz8/Y7XZzyy23mEGDBjk9Or1//37zwAMPmNKlSxsPDw/TtGlT880332Q5Xn9/nDq78c3qfCSZQYMGmU8++cTUrFnT2O12ExISkuXPIDEx0QwaNMgEBQU53hMdOnQwM2bMuGZNBw8edHqPHzhwwPTv399Ur17deHh4mLJly5r27dubb7/91mm7r776yjRs2NB4eHiYatWqmTfeeMPxUQUHDx40xvz1nuvVq5epUqWKsdvtxt/f39x1111Oj7cDWbEZk08z/AAAhYbNZtOgQYOyvAUJWB1zbgAAgKUQbgAAgKUQbgAAgKXwtBQAWBDTKXEz48oNAACwFMINAACwlJvutlR6erqOHTumUqVK5fvH5AMAgBvDGKM///xTFStWvOYHXt504ebYsWP58j04AACg4B05ckSVK1e+ap+bLtyUKlVK0l+Dkx/fhwMAAG685ORkBQUFOf4dv5qbLtxk3Iry8fEh3AAAUMTkZEoJE4oBAIClEG4AAIClEG4AAIClEG4AAIClEG4AAIClEG4AAIClEG4AAIClEG4AAIClEG4AAIClEG4AAIClEG4AAICluDTcTJ06VQ0bNnR8z1NYWJiWLVt21W3mz5+v2rVry8PDQw0aNNDSpUsLqFoAAFAUuDTcVK5cWa+//rq2bdumrVu36o477lD37t21c+fOLPtv2LBBvXr10oABAxQbG6sePXqoR48e2rFjRwFXDgAACiubMca4uogrlS1bVm+++aYGDBiQad1DDz2klJQUffPNN4625s2bq3Hjxpo2bVqO9p+cnCxfX18lJSXxreAAABQRufn3u3gB1XRNly9f1vz585WSkqKwsLAs+2zcuFERERFObeHh4Vq0aFG2+01NTVVqaqpjOTk5OV/qzU58fLxOnTp1Q4+R38qXL68qVaq4ugwAAPKFy8PNzz//rLCwMF24cEHe3t768ssvVbdu3Sz7JiQkKCAgwKktICBACQkJ2e4/KipKY8aMydeasxMfH69atevowvlzBXK8/OLh6aU9v+wm4AAALMHl4aZWrVqKi4tTUlKSFixYoD59+mjt2rXZBpzcioyMdLrak5ycrKCgoHzZ99+dOnVKF86fU7m7hsm93I05Rn67ePqITn8zQadOnSLcAAAsweXhpkSJEqpRo4YkKTQ0VFu2bNGUKVM0ffr0TH0DAwOVmJjo1JaYmKjAwMBs92+322W32/O36GtwLxcke2CNAj0mAAD4S6H7nJv09HSnOTJXCgsLU0xMjFNbdHR0tnN0AADAzcelV24iIyPVtWtXValSRX/++afmzJmjNWvWaMWKFZKk3r17q1KlSoqKipIkPfvss2rbtq0mTJigbt266fPPP9fWrVs1Y8YMV54GAAAoRFwabk6cOKHevXvr+PHj8vX1VcOGDbVixQp16tRJ0l8TdN3c/ndxqUWLFpozZ45eeukljRw5UjVr1tSiRYtUv359V50CAAAoZFwabv773/9edf2aNWsytfXs2VM9e/a8QRUBAICirtDNuQEAALgehBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGAphBsAAGApLg03UVFRuv3221WqVCn5+/urR48e2rNnz1W3mT17tmw2m9PLw8OjgCoGAACFnUvDzdq1azVo0CBt2rRJ0dHRunjxojp37qyUlJSrbufj46Pjx487XocPHy6gigEAQGFX3JUHX758udPy7Nmz5e/vr23btqlNmzbZbmez2RQYGJijY6Smpio1NdWxnJycnLdiAQBAkVCo5twkJSVJksqWLXvVfmfPnlXVqlUVFBSk7t27a+fOndn2jYqKkq+vr+MVFBSUrzUDAIDCpdCEm/T0dA0dOlQtW7ZU/fr1s+1Xq1YtzZw5U4sXL9Ynn3yi9PR0tWjRQr/99luW/SMjI5WUlOR4HTly5EadAgAAKARcelvqSoMGDdKOHTv0/fffX7VfWFiYwsLCHMstWrRQnTp1NH36dL366quZ+tvtdtnt9nyvFwAAFE6FItwMHjxY33zzjdatW6fKlSvnalt3d3eFhIRo3759N6g6AABQlLj0tpQxRoMHD9aXX36pVatWKTg4ONf7uHz5sn7++WdVqFDhBlQIAACKGpdeuRk0aJDmzJmjxYsXq1SpUkpISJAk+fr6ytPTU5LUu3dvVapUSVFRUZKksWPHqnnz5qpRo4bOnDmjN998U4cPH9bjjz/usvMAAACFh0vDzdSpUyVJ7dq1c2qfNWuW+vbtK0mKj4+Xm9v/LjD98ccfGjhwoBISElSmTBmFhoZqw4YNqlu3bkGVDQAACjGXhhtjzDX7rFmzxml50qRJmjRp0g2qCAAAFHWF5lFwAACA/EC4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAluLScBMVFaXbb79dpUqVkr+/v3r06KE9e/Zcc7v58+erdu3a8vDwUIMGDbR06dICqBYAABQFLg03a9eu1aBBg7Rp0yZFR0fr4sWL6ty5s1JSUrLdZsOGDerVq5cGDBig2NhY9ejRQz169NCOHTsKsHIAAFBYFXflwZcvX+60PHv2bPn7+2vbtm1q06ZNlttMmTJFXbp00fDhwyVJr776qqKjo/XOO+9o2rRpN7xmAABQuLk03PxdUlKSJKls2bLZ9tm4caMiIiKc2sLDw7Vo0aIs+6empio1NdWxnJycfP2FAgBQQOLj43Xq1ClXl5Er5cuXV5UqVVx2/EITbtLT0zV06FC1bNlS9evXz7ZfQkKCAgICnNoCAgKUkJCQZf+oqCiNGTMmX2sFAKAgxMfHq1btOrpw/pyrS8kVD08v7fllt8sCTqEJN4MGDdKOHTv0/fff5+t+IyMjna70JCcnKygoKF+PAQDAjXDq1CldOH9O5e4aJvdyRePfrounj+j0NxN06tSpmzvcDB48WN98843WrVunypUrX7VvYGCgEhMTndoSExMVGBiYZX+73S673Z5vtQIAUNDcywXJHljD1WUUGS59WsoYo8GDB+vLL7/UqlWrFBwcfM1twsLCFBMT49QWHR2tsLCwG1UmAAAoQlx65WbQoEGaM2eOFi9erFKlSjnmzfj6+srT01OS1Lt3b1WqVElRUVGSpGeffVZt27bVhAkT1K1bN33++efaunWrZsyY4bLzAAAAhYdLr9xMnTpVSUlJateunSpUqOB4zZ0719EnPj5ex48fdyy3aNFCc+bM0YwZM9SoUSMtWLBAixYtuuokZAAAcPNw6ZUbY8w1+6xZsyZTW8+ePdWzZ88bUBEAACjq+G4pAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKXn++oWUlBStXbtW8fHxSktLc1o3ZMiQ6y4MAAAgL/IUbmJjY3XnnXfq3LlzSklJUdmyZXXq1Cl5eXnJ39+fcAMAAFwmT7elnnvuOd199936448/5OnpqU2bNunw4cMKDQ3VW2+9ld81AgAA5Fiewk1cXJyGDRsmNzc3FStWTKmpqQoKCtL48eM1cuTI/K4RAAAgx/IUbtzd3eXm9tem/v7+io+PlyT5+vrqyJEj+VcdAABALuVpzk1ISIi2bNmimjVrqm3btho1apROnTqljz/+WPXr18/vGgEAAHIsT1duXnvtNVWoUEGSNG7cOJUpU0b//Oc/dfLkSc2YMSNfCwQAAMiNPF25adKkiePP/v7+Wr58eb4VBAAAcD34ED8AAGApOb5yc9tttykmJkZlypRRSEiIbDZbtn23b9+eL8UBAADkVo7DTffu3WW32yVJPXr0uFH1AAAAXJcch5vRo0dn+WcAAIDCJE9zbrZs2aIffvghU/sPP/ygrVu3XndRAAAAeZWncDNo0KAsP6zv6NGjGjRo0HUXBQAAkFd5Cje7du3Sbbfdlqk9JCREu3btuu6iAAAA8ipP4cZutysxMTFT+/Hjx1W8eJ4+OgcAACBf5CncdO7cWZGRkUpKSnK0nTlzRiNHjlSnTp3yrTgAAIDcytNllrfeektt2rRR1apVFRISIumvbwoPCAjQxx9/nK8FAgAA5Eaewk2lSpX0008/6dNPP9WPP/4oT09P9evXT7169ZK7u3t+1wgAAJBjeZ4gU7JkST3xxBP5WQsAAMB1y3O42bt3r1avXq0TJ04oPT3dad2oUaOuuzAAAIC8yFO4ef/99/XPf/5T5cuXV2BgoNP3TNlsNsINAABwmTyFm3//+98aN26cnn/++fyuBwAA4Lrk6VHwP/74Qz179szvWgAAAK5bnsJNz549tXLlyvyuBQAA4Lrl6bZUjRo19PLLL2vTpk1q0KBBpse/hwwZki/FAQAA5Faews2MGTPk7e2ttWvXau3atU7rbDYb4QYAALhMnsLNwYMH87sOAACAfJGnOTcZ0tLStGfPHl26dCm/6gEAALgueQo3586d04ABA+Tl5aV69eopPj5ekvTMM8/o9ddfz9cCAQAAciNP4SYyMlI//vij1qxZIw8PD0d7x44dNXfu3HwrDgAAILfyNOdm0aJFmjt3rpo3b+706cT16tXT/v378604AACA3MrTlZuTJ0/K398/U3tKSopT2AEAAChoeQo3TZo00ZIlSxzLGYHmgw8+UFhYWP5UBgAAkAd5ui312muvqWvXrtq1a5cuXbqkKVOmaNeuXdqwYUOmz70BAAAoSHm6ctOqVSvFxcXp0qVLatCggVauXCl/f39t3LhRoaGh+V0jAABAjuXpyo0kVa9eXe+//35+1gIAAHDd8hRuMj7XJjtVqlTJUzEAAADXK0+3papVq6bg4OBsXzm1bt063X333apYsaJsNpsWLVp01f5r1qyRzWbL9EpISMjLaQAAAAvK05Wb2NhYp+WLFy8qNjZWEydO1Lhx43K8n5SUFDVq1Ej9+/fXfffdl+Pt9uzZIx8fH8dyVo+lAwCAm1Oewk2jRo0ytTVp0kQVK1bUm2++meOg0rVrV3Xt2jXXx/f391fp0qVzvR0AALC+6/rizL+rVauWtmzZkp+7zFLjxo1VoUIFderUSevXr79q39TUVCUnJzu9AACAdeUp3Pw9LCQlJemXX37RSy+9pJo1a+Z3jQ4VKlTQtGnTtHDhQi1cuFBBQUFq166dtm/fnu02UVFR8vX1dbyCgoJuWH0AAMD18nRbqnTp0pm+ZsEYo6CgIH3++ef5UlhWatWqpVq1ajmWW7Roof3792vSpEn6+OOPs9wmMjJSERERjuXk5GQCDgAAFpancLNq1SqncOPm5iY/Pz/VqFFDxYvn+aNz8qRp06b6/vvvs11vt9tlt9sLsCIAAOBKeUoi7dq1y+cy8i4uLk4VKlRwdRkAAKCQyFO4iYqKUkBAgPr37+/UPnPmTJ08eVLPP/98jvZz9uxZ7du3z7F88OBBxcXFqWzZsqpSpYoiIyN19OhRffTRR5KkyZMnKzg4WPXq1dOFCxf0wQcfaNWqVVq5cmVeTgMAAFhQniYUT58+XbVr187UXq9ePU2bNi3H+9m6datCQkIUEhIiSYqIiFBISIhGjRolSTp+/LjTpyGnpaVp2LBhatCggdq2basff/xR3377rTp06JCX0wAAABaUpys3CQkJWd4K8vPz0/Hjx3O8n3bt2skYk+362bNnOy2PGDFCI0aMyPH+AQDAzSdPV26CgoKy/HyZ9evXq2LFitddFAAAQF7l6crNwIEDNXToUF28eFF33HGHJCkmJkYjRozQsGHD8rVAAACA3MhTuBk+fLhOnz6tp59+WmlpaZIkDw8PPf/884qMjMzXAgEAAHIjT+HGZrPpjTfe0Msvv6zdu3fL09NTNWvW5PNkAACAy13Xd0slJCTo999/V/Xq1WW32686ORgAAKAg5CncnD59Wh06dNCtt96qO++80/GE1IABA5hzAwAAXCpP4ea5556Tu7u74uPj5eXl5Wh/6KGHtHz58nwrDgAAILfyNOdm5cqVWrFihSpXruzUXrNmTR0+fDhfCgMAAMiLPF25SUlJcbpik+H3339nUjEAAHCpPIWb1q1bO77vSfrr6an09HSNHz9e7du3z7fiAAAAcitPt6XGjx+vDh06aOvWrUpLS9OIESO0c+dO/f7771l+cjEAAEBBydOVm/r16+vXX39Vq1at1L17d6WkpOi+++5TbGysqlevnt81AgAA5Fiur9xcvHhRXbp00bRp0/Tiiy/eiJoAAADyLNdXbtzd3fXTTz/diFoAAACuW55uSz322GP673//m9+1AAAAXLc8TSi+dOmSZs6cqW+//VahoaEqWbKk0/qJEyfmS3EAAAC5latwc+DAAVWrVk07duzQbbfdJkn69ddfnfrYbLb8qw4AACCXchVuatasqePHj2v16tWS/vq6hf/85z8KCAi4IcUBAADkVq7m3Pz9W7+XLVumlJSUfC0IAADgeuRpQnGGv4cdAAAAV8tVuLHZbJnm1DDHBgAAFCa5mnNjjFHfvn0dX4554cIFPfXUU5melvriiy/yr0IAAIBcyFW46dOnj9PyY489lq/FAAAAXK9chZtZs2bdqDoAAADyxXVNKAYAAChsCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSXBpu1q1bp7vvvlsVK1aUzWbTokWLrrnNmjVrdNttt8lut6tGjRqaPXv2Da8TAAAUHS4NNykpKWrUqJHefffdHPU/ePCgunXrpvbt2ysuLk5Dhw7V448/rhUrVtzgSgEAQFFR3JUH79q1q7p27Zrj/tOmTVNwcLAmTJggSapTp46+//57TZo0SeHh4Vluk5qaqtTUVMdycnLy9RWNQiE+Pl6nTp1ydRm5Ur58eVWpUsXVZVheUXxvpKamym63u7qMXCmKNUtFr+7du3e7uoQiyaXhJrc2btyojh07OrWFh4dr6NCh2W4TFRWlMWPG3ODKUJDi4+NVq3YdXTh/ztWl5IqHp5f2/LKbgHMDFdX3hmxukkl3dRW5UxRrlopu3ciVIhVuEhISFBAQ4NQWEBCg5ORknT9/Xp6enpm2iYyMVEREhGM5OTlZQUFBN7xW3DinTp3ShfPnVO6uYXIvVzR+lhdPH9Hpbybo1KlThJsbqCi+N84f2Kqk7z6h5gJQFOvOqBm5U6TCTV7Y7fYidQkSOedeLkj2wBquLgOFUFF6b1w8fUQSNReEolh3Rs3InSL1KHhgYKASExOd2hITE+Xj45PlVRsAAHDzKVLhJiwsTDExMU5t0dHRCgsLc1FFAACgsHFpuDl79qzi4uIUFxcn6a9HvePi4hQfHy/pr/kyvXv3dvR/6qmndODAAY0YMUK//PKL3nvvPc2bN0/PPfecK8oHAACFkEvDzdatWxUSEqKQkBBJUkREhEJCQjRq1ChJ0vHjxx1BR5KCg4O1ZMkSRUdHq1GjRpowYYI++OCDbB8DBwAANx+XTihu166djDHZrs/q04fbtWun2NjYG1gVAAAoyorUnBsAAIBrIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLKRTh5t1331W1atXk4eGhZs2aafPmzdn2nT17tmw2m9PLw8OjAKsFAACFmcvDzdy5cxUREaHRo0dr+/btatSokcLDw3XixIlst/Hx8dHx48cdr8OHDxdgxQAAoDBzebiZOHGiBg4cqH79+qlu3bqaNm2avLy8NHPmzGy3sdlsCgwMdLwCAgIKsGIAAFCYuTTcpKWladu2berYsaOjzc3NTR07dtTGjRuz3e7s2bOqWrWqgoKC1L17d+3cuTPbvqmpqUpOTnZ6AQAA63JpuDl16pQuX76c6cpLQECAEhISstymVq1amjlzphYvXqxPPvlE6enpatGihX777bcs+0dFRcnX19fxCgoKyvfzAAAAhYfLb0vlVlhYmHr37q3GjRurbdu2+uKLL+Tn56fp06dn2T8yMlJJSUmO15EjRwq4YgAAUJCKu/Lg5cuXV7FixZSYmOjUnpiYqMDAwBztw93dXSEhIdq3b1+W6+12u+x2+3XXCgAAigaXXrkpUaKEQkNDFRMT42hLT09XTEyMwsLCcrSPy5cv6+eff1aFChVuVJkAAKAIcemVG0mKiIhQnz591KRJEzVt2lSTJ09WSkqK+vXrJ0nq3bu3KlWqpKioKEnS2LFj1bx5c9WoUUNnzpzRm2++qcOHD+vxxx935WkAAIBCwuXh5qGHHtLJkyc1atQoJSQkqHHjxlq+fLljknF8fLzc3P53gemPP/7QwIEDlZCQoDJlyig0NFQbNmxQ3bp1XXUKAACgEHF5uJGkwYMHa/DgwVmuW7NmjdPypEmTNGnSpAKoCgAAFEVF7mkpAACAqyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASykU4ebdd99VtWrV5OHhoWbNmmnz5s1X7T9//nzVrl1bHh4eatCggZYuXVpAlQIAgMLO5eFm7ty5ioiI0OjRo7V9+3Y1atRI4eHhOnHiRJb9N2zYoF69emnAgAGKjY1Vjx491KNHD+3YsaOAKwcAAIWRy8PNxIkTNXDgQPXr109169bVtGnT5OXlpZkzZ2bZf8qUKerSpYuGDx+uOnXq6NVXX9Vtt92md955p4ArBwAAhVFxVx48LS1N27ZtU2RkpKPNzc1NHTt21MaNG7PcZuPGjYqIiHBqCw8P16JFi7Lsn5qaqtTUVMdyUlKSJCk5Ofk6q8/s7Nmzfx0zYZ/S0y7k+/5vhIu//yZJ2rZtm6P+wm7Pnj2SGOeC4ObmpvT0dFeXkWNF8r1x+ogkai4IRbHuIlnz//++O3v2bL7+W5uxL2PMtTsbFzp69KiRZDZs2ODUPnz4cNO0adMst3F3dzdz5sxxanv33XeNv79/lv1Hjx5tJPHixYsXL168LPA6cuTINfOFS6/cFITIyEinKz3p6en6/fffVa5cOdlsNhdWVngkJycrKChIR44ckY+Pj6vLsSTGuGAwzgWDcb7xGOPMjDH6888/VbFixWv2dWm4KV++vIoVK6bExESn9sTERAUGBma5TWBgYK762+122e12p7bSpUvnvWgL8/Hx4S/RDcYYFwzGuWAwzjceY+zM19c3R/1cOqG4RIkSCg0NVUxMjKMtPT1dMTExCgsLy3KbsLAwp/6SFB0dnW1/AABwc3H5bamIiAj16dNHTZo0UdOmTTV58mSlpKSoX79+kqTevXurUqVKioqKkiQ9++yzatu2rSZMmKBu3brp888/19atWzVjxgxXngYAACgkXB5uHnroIZ08eVKjRo1SQkKCGjdurOXLlysgIECSFB8fLze3/11gatGihebMmaOXXnpJI0eOVM2aNbVo0SLVr1/fVadQ5Nntdo0ePTrT7TvkH8a4YDDOBYNxvvEY4+tjMyYnz1QBAAAUDS7/ED8AAID8RLgBAACWQrgBAACWQrgBAACWQri5SRw6dEgDBgxQcHCwPD09Vb16dY0ePVppaWlOfWw2W6bXpk2bnPY1f/581a5dWx4eHmrQoIGWLl1a0KdTaOVknCXpp59+UuvWreXh4aGgoCCNHz8+074Y56sbN26cWrRoIS8vr2w/mDOr9/Pnn3/u1GfNmjW67bbbZLfbVaNGDc2ePfvGF19E5GSM4+Pj1a1bN3l5ecnf31/Dhw/XpUuXnPowxrlTrVq1TO/b119/3alPTn6H3NRy8h1QKPqWLVtm+vbta1asWGH2799vFi9ebPz9/c2wYcMcfQ4ePGgkmW+//dYcP37c8UpLS3P0Wb9+vSlWrJgZP3682bVrl3nppZeMu7u7+fnnn11xWoVOTsY5KSnJBAQEmEcffdTs2LHDfPbZZ8bT09NMnz7d0YdxvrZRo0aZiRMnmoiICOPr65tlH0lm1qxZTu/n8+fPO9YfOHDAeHl5mYiICLNr1y7z9ttvm2LFipnly5cX0FkUbtca40uXLpn69eubjh07mtjYWLN06VJTvnx5ExkZ6ejDGOde1apVzdixY53et2fPnnWsz8nvkJsd4eYmNn78eBMcHOxYzgg3sbGx2W7z4IMPmm7dujm1NWvWzDz55JM3qswi7+/j/N5775kyZcqY1NRUR9vzzz9vatWq5VhmnHNu1qxZVw03X375ZbbbjhgxwtSrV8+p7aGHHjLh4eH5WGHRl90YL1261Li5uZmEhARH29SpU42Pj4/j/c0Y517VqlXNpEmTsl2fk98hNztuS93EkpKSVLZs2Uzt99xzj/z9/dWqVSt99dVXTus2btyojh07OrWFh4dr48aNN7TWouzv47xx40a1adNGJUqUcLSFh4drz549+uOPPxx9GOf8MWjQIJUvX15NmzbVzJkzZa74aC/G+fps3LhRDRo0cHzoqvTX+CUnJ2vnzp2OPoxx7r3++usqV66cQkJC9Oabbzrd6svJ75Cbncs/oRiusW/fPr399tt66623HG3e3t6aMGGCWrZsKTc3Ny1cuFA9evTQokWLdM8990iSEhISnH6RSVJAQIASEhIKtP6iIqtxTkhIUHBwsFO/jDFNSEhQmTJlGOd8MnbsWN1xxx3y8vLSypUr9fTTT+vs2bMaMmSIpOzfz8nJyTp//rw8PT1dUXaRkd34Zay7Wh/GOHtDhgzRbbfdprJly2rDhg2KjIzU8ePHNXHiREk5+x1ys+PKTRH3wgsvZDlp8srXL7/84rTN0aNH1aVLF/Xs2VMDBw50tJcvX14RERFq1qyZbr/9dr3++ut67LHH9Oabbxb0aRU6+TnOyF5exvlqXn75ZbVs2VIhISF6/vnnNWLEiJv+/ZzfY4ycyc24R0REqF27dmrYsKGeeuopTZgwQW+//bZSU1NdfBZFB1duirhhw4apb9++V+1zyy23OP587NgxtW/fXi1atMjRl402a9ZM0dHRjuXAwEAlJiY69UlMTFRgYGDuCi9i8nOcsxvDjHVX68M4O49zbjVr1kyvvvqqUlNTZbfbsx1nHx8fy15RyM8xDgwM1ObNm53acvpetvIYZ+V6xr1Zs2a6dOmSDh06pFq1auXod8jNjnBTxPn5+cnPzy9HfY8ePar27dsrNDRUs2bNcvpC0uzExcWpQoUKjuWwsDDFxMRo6NChjrbo6GiFhYXluvaiJD/HOSwsTC+++KIuXrwod3d3SX+NYa1atRyXkxnnGyMuLk5lypRxfBlhWFhYpkfsrT7O+TnGYWFhGjdunE6cOCF/f39Jf42fj4+P6tat6+hzs41xVq5n3OPi4uTm5uYY45z8DrnpuXpGMwrGb7/9ZmrUqGE6dOhgfvvtN6dHDDPMnj3bzJkzx+zevdvs3r3bjBs3zri5uZmZM2c6+qxfv94UL17cvPXWW2b37t1m9OjRPKJ8hZyM85kzZ0xAQID5xz/+YXbs2GE+//xz4+XllelRcMb56g4fPmxiY2PNmDFjjLe3t4mNjTWxsbHmzz//NMYY89VXX5n333/f/Pzzz2bv3r3mvffeM15eXmbUqFGOfWQ8pjx8+HCze/du8+677/KY8hWuNcYZj4J37tzZxMXFmeXLlxs/P78sHwVnjHNmw4YNZtKkSSYuLs7s37/ffPLJJ8bPz8/07t3b0Scnv0NudoSbm8SsWbOMpCxfGWbPnm3q1KljvLy8jI+Pj2natKmZP39+pn3NmzfP3HrrraZEiRKmXr16ZsmSJQV5KoVaTsbZGGN+/PFH06pVK2O3202lSpXM66+/nmlfjPPV9enTJ8txXr16tTHmr88caty4sfH29jYlS5Y0jRo1MtOmTTOXL1922s/q1atN48aNTYkSJcwtt9xiZs2aVfAnU0hda4yNMebQoUOma9euxtPT05QvX94MGzbMXLx40Wk/jHHObdu2zTRr1sz4+voaDw8PU6dOHfPaa6+ZCxcuOPXLye+Qm5nNmCueiwQAACjieFoKAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGwDX17dtXNptNNptN7u7uCg4O1ogRI3ThwgVXlwYAmfCt4ABypEuXLpo1a5YuXryobdu2qU+fPrLZbHrjjTdcXRoAOOHKDYAcsdvtCgwMVFBQkHr06KGOHTsqOjpakpSenq6oqCgFBwfL09NTjRo10oIFC5y237lzp+666y75+PioVKlSat26tfbv3+/YfuzYsapcubLsdrsaN26s5cuXO7Y9dOiQbDab5s2bp9atW8vT01O33367fv31V23ZskVNmjSRt7e3unbtqpMnTzq269u3r3r06KExY8bIz89PPj4+euqpp5SWluboc63a16xZI5vNppiYGDVp0kReXl5q0aKF9uzZ4+jz448/qn379ipVqpR8fHwUGhqqrVu3SpJOnz6tXr16qVKlSvLy8lKDBg302Wef5eNPBsDfEW4A5NqOHTu0YcMGlShRQpIUFRWljz76SNOmTdPOnTv13HPP6bHHHtPatWslSUePHlWbNm1kt9u1atUqbdu2Tf3799elS5ckSVOmTNGECRP01ltv6aefflJ4eLjuuece7d271+m4o0eP1ksvvaTt27erePHieuSRRzRixAhNmTJF3333nfbt26dRo0Y5bRMTE6Pdu3drzZo1+uyzz/TFF19ozJgxjvXXqj3Diy++qAkTJmjr1q0qXry4+vfv71j36KOPqnLlytqyZYu2bdumF154Qe7u7pKkCxcuKDQ0VEuWLNGOHTv0xBNP6B//+Ic2b96cTz8NAJm4+mvJARR+ffr0McWKFTMlS5Y0drvdSDJubm5mwYIF5sKFC8bLy8ts2LDBaZsBAwaYXr16GWOMiYyMNMHBwSYtLS3L/VesWNGMGzfOqe322283Tz/9tDHGmIMHDxpJ5oMPPnCs/+yzz4wkExMT42iLiooytWrVcqq7bNmyJiUlxdE2depU4+3tbS5fvpyj2levXm0kmW+//daxfsmSJUaSOX/+vDHGmFKlSpnZs2dfYxT/p1u3bmbYsGE57g8gd5hzAyBH2rdvr6lTpyolJUWTJk1S8eLFdf/992vnzp06d+6cOnXq5NQ/LS1NISEhkqS4uDi1bt3acTXjSsnJyTp27Jhatmzp1N6yZUv9+OOPTm0NGzZ0/DkgIECS1KBBA6e2EydOOG3TqFEjeXl5OZbDwsJ09uxZHTlyRGfPnr1m7Vkdu0KFCpKkEydOqEqVKoqIiNDjjz+ujz/+WB07dlTPnj1VvXp1SdLly5f12muvad68eTp69KjS0tKUmprqVBOA/EW4AZAjJUuWVI0aNSRJM2fOVKNGjfTf//5X9evXlyQtWbJElSpVctrGbrdLkjw9PfOlhivDkc1my7ItPT09x/s7e/aspKvXfrVjZxzrlVde0SOPPKIlS5Zo2bJlGj16tD7//HPde++9evPNNzVlyhRNnjxZDRo0UMmSJTV06FCneT8A8hfhBkCuubm5aeTIkYqIiNCvv/4qu92u+Ph4tW3bNsv+DRs21IcffqiLFy9munrj4+OjihUrav369U7br1+/Xk2bNr3uWn/88UedP3/eEbA2bdokb29vBQUFqWzZstesPaduvfVW3XrrrXruuefUq1cvzZo1S/fee6/Wr1+v7t2767HHHpP0VyD69ddfVbdu3es+NwBZY0IxgDzp2bOnihUrpunTp+tf//qXnnvuOX344Yfav3+/tm/frrffflsffvihJGnw4MFKTk7Www8/rK1bt2rv3r36+OOPHU8cDR8+XG+88Ybmzp2rPXv26IUXXlBcXJyeffbZ664zLS1NAwYM0K5du7R06VKNHj1agwcPlpubm0qVKnXN2q/l/PnzGjx4sNasWaPDhw9r/fr12rJli+rUqSNJqlmzpqKjo7Vhwwbt3r1bTz75pBITE6/7vABkjys3APKkePHiGjx4sMaPH6+DBw/Kz89PUVFROnDggEqXLq3bbrtNI0eOlCSVK1dOq1at0vDhw9W2bVsVK1ZMjRs3dsyzGTJkiJKSkjRs2DCdOHFCdevW1VdffaWaNWted50dOnRQzZo11aZNG6WmpqpXr1565ZVXHOtfffXVq9Z+LcWKFdPp06fVu3dvJSYmqnz58rrvvvscT2S99NJLOnDggMLDw+Xl5aUnnnhCPXr0UFJS0nWfG4Cs2YwxxtVFAMCN0LdvX505c0aLFi1ydSkAChC3pQAAgKUQbgAAgKVwWwoAAFgKV24AAIClEG4AAIClEG4AAIClEG4AAIClEG4AAIClEG4AAIClEG4AAIClEG4AAICl/B9fOK/iWTMx+QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_episodes = 10\n",
    "rewards = []\n",
    "\n",
    "for _ in range(num_episodes):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    \n",
    "    while not done:\n",
    "        action = env.action_space.sample() \n",
    "        obs, reward, done, truncated, info = env.step(action)\n",
    "        total_reward += reward\n",
    "    \n",
    "    rewards.append(total_reward)\n",
    "\n",
    "mean_reward = np.mean(rewards)\n",
    "std_reward = np.std(rewards)\n",
    "\n",
    "print(f\"Promedio de las recompensas: {mean_reward}\")\n",
    "print(f\"Desviaci贸n est谩ndar de las recompensas: {std_reward}\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(rewards, bins=10, edgecolor='black')\n",
    "plt.title('Distribuci贸n de Recompensas')\n",
    "plt.xlabel('Recompensa')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "El performance de la pol铆tica de acciones aleatorias en el ambiente de LunarLander es bastante pobre. Esto se refleja en el promedio de recompensas obtenido, que es de -149.31, con una desviaci贸n est谩ndar de 91.36.\n",
    "\n",
    "### Interpretaci贸n de las Recompensas Obtenidas\n",
    "\n",
    "- **Promedio de Recompensas**: Un promedio negativo indica que, en general, el agente no est谩 logrando aterrizar correctamente y est谩 acumulando penalizaciones. Esto es esperable dado que las acciones se seleccionan de manera aleatoria, sin ninguna estrategia que maximice las recompensas.\n",
    "- **Desviaci贸n Est谩ndar**: La desviaci贸n est谩ndar de 91.36 sugiere que hay una variabilidad considerable en las recompensas obtenidas. Esto significa que, aunque el agente tiene un desempe帽o generalmente pobre, hay episodios en los que puede obtener recompensas menos negativas, pero estos son menos frecuentes.\n",
    "\n",
    "La pol铆tica de acciones aleatorias no es efectiva para el ambiente de LunarLander, ya que no sigue ninguna estrategia que le permita maximizar sus recompensas. Para mejorar el performance, ser铆a necesario implementar una pol铆tica m谩s informada o entrenar un modelo de aprendizaje por refuerzo que aprenda a tomar decisiones 贸ptimas en este ambiente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hQrZVQflX_5f"
   },
   "source": [
    "#### **1.2.3 Entrenamiento de modelo (0.2 puntos)**\n",
    "\n",
    "A partir del siguiente [enlace](https://stable-baselines3.readthedocs.io/en/master/guide/algos.html), escoja un modelo de `stable_baselines3` y entrenelo para resolver el ambiente `LunarLander` **usando 10000 timesteps de entrenamiento**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y_6Ia9uoF7Hs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 110      |\n",
      "|    ep_rew_mean     | -312     |\n",
      "| time/              |          |\n",
      "|    fps             | 430      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 131          |\n",
      "|    ep_rew_mean          | -283         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 336          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044293585 |\n",
      "|    clip_fraction        | 0.0441       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | -0.00169     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 947          |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00545     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 2.66e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 123        |\n",
      "|    ep_rew_mean          | -254       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 323        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 18         |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00458639 |\n",
      "|    clip_fraction        | 0.0196     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.84      |\n",
      "|    explained_variance   | 0.0474     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 301        |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.00466   |\n",
      "|    std                  | 0.998      |\n",
      "|    value_loss           | 1.01e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 117          |\n",
      "|    ep_rew_mean          | -228         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 311          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 26           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042363214 |\n",
      "|    clip_fraction        | 0.0159       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | -0.0111      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 483          |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00464     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 1.23e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 120          |\n",
      "|    ep_rew_mean          | -227         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 278          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 36           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054229833 |\n",
      "|    clip_fraction        | 0.034        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | -0.00426     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 423          |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00649     |\n",
      "|    std                  | 0.989        |\n",
      "|    value_loss           | 1.02e+03     |\n",
      "------------------------------------------\n",
      "Recompensa obtenida: [0.23761007]\n",
      "Recompensa obtenida: [0.11142506]\n",
      "Recompensa obtenida: [-0.01280054]\n",
      "Recompensa obtenida: [-0.14588319]\n",
      "Recompensa obtenida: [-0.28416595]\n",
      "Recompensa obtenida: [-0.42458382]\n",
      "Recompensa obtenida: [-0.5638137]\n",
      "Recompensa obtenida: [-0.6986253]\n",
      "Recompensa obtenida: [-0.82617736]\n",
      "Recompensa obtenida: [-0.9441384]\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "env = make_vec_env(lambda: gym.make(\"LunarLander-v2\", render_mode=\"rgb_array\", continuous=True), n_envs=1)\n",
    "\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=10000)\n",
    "model.save(\"ppo_lunarlander_model\")\n",
    "\n",
    "obs = env.reset()\n",
    "for _ in range(10):  # Jugar 10 episodios\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    print(f\"Recompensa obtenida: {rewards}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3z-oIUSrlAsY"
   },
   "source": [
    "#### **1.2.4 Evaluaci贸n de modelo (0.2 puntos)**\n",
    "\n",
    "Repita el ejercicio 1.2.2 pero utilizando el modelo entrenado. 驴C贸mo es el performance de su agente? 驴Es mejor o peor que el escenario baseline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ophyU3KrWrwl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recompensa media: -190.11721930000002\n",
      "Desviaci贸n est谩ndar de la recompensa: 84.08649838206992\n",
      "Promedio de las recompensas: -176.3380584716797\n",
      "Desviaci贸n est谩ndar de las recompensas: 95.14295196533203\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=10)\n",
    "\n",
    "print(f\"Recompensa media: {mean_reward}\")\n",
    "print(f\"Desviaci贸n est谩ndar de la recompensa: {std_reward}\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rewards = []\n",
    "for _ in range(num_episodes):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    \n",
    "    while not done:\n",
    "        action, _states = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        total_reward += reward\n",
    "    \n",
    "    rewards.append(total_reward)\n",
    "\n",
    "mean_reward = np.mean(rewards)\n",
    "std_reward = np.std(rewards)\n",
    "\n",
    "print(f\"Promedio de las recompensas: {mean_reward}\")\n",
    "print(f\"Desviaci贸n est谩ndar de las recompensas: {std_reward}\")\n",
    "\n",
    "plt.hist(rewards, bins=10, edgecolor='black')\n",
    "plt.title('Distribuci贸n de Recompensas')\n",
    "plt.xlabel('Recompensa')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El performance del agente entrenado utilizando el modelo PPO es significativamente mejor que el escenario baseline de acciones aleatorias. Esto se refleja en la recompensa media obtenida, que es de -176.34, con una desviaci贸n est谩ndar de 95.14.\n",
    "\n",
    "### Comparaci贸n con el Baseline\n",
    "\n",
    "- **Promedio de Recompensas**: El promedio de recompensas del agente entrenado es mejor que el promedio negativo del baseline (-149.31). Esto indica que el agente entrenado tiene un mejor desempe帽o general.\n",
    "- **Desviaci贸n Est谩ndar**: La desviaci贸n est谩ndar de las recompensas del agente entrenado es mayor que la del baseline (95.14 vs. 91.36). Esto sugiere que hay una mayor variabilidad en las recompensas obtenidas, lo cual es esperable dado que el agente est谩 tomando decisiones m谩s informadas y, por lo tanto, puede obtener mejores recompensas en algunos episodios.\n",
    "\n",
    "En resumen, el agente entrenado con PPO muestra un mejor performance en comparaci贸n con la pol铆tica de acciones aleatorias, lo que demuestra la efectividad del modelo de RL en aprender una estrategia para el ambiente de LunarLander."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x6Xw4YHT3P5d"
   },
   "source": [
    "#### **1.2.5 Optimizaci贸n de modelo (0.2 puntos)**\n",
    "\n",
    "Repita los ejercicios 1.2.3 y 1.2.4 hasta obtener un nivel de recompensas promedio mayor a 50. Para esto, puede cambiar manualmente par谩metros como:\n",
    "- `total_timesteps`\n",
    "- `learning_rate`\n",
    "- `batch_size`\n",
    "\n",
    "Una vez optimizado el modelo, use la funci贸n `export_gif` para estudiar el comportamiento de su agente en la resoluci贸n del ambiente y comente sobre sus resultados.\n",
    "\n",
    "Adjunte el gif generado en su entrega (mejor a煤n si adem谩s adjuntan el gif en el markdown)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "aItYF6sr6F_6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 118      |\n",
      "|    ep_rew_mean     | -297     |\n",
      "| time/              |          |\n",
      "|    fps             | 451      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 122          |\n",
      "|    ep_rew_mean          | -258         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 397          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012328704 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0.00411      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.18e+03     |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00165     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 2.33e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 140          |\n",
      "|    ep_rew_mean          | -253         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 349          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042367755 |\n",
      "|    clip_fraction        | 0.0114       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | -0.00391     |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 719          |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00399     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 1.75e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 139           |\n",
      "|    ep_rew_mean          | -233          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 355           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 23            |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00073244097 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.84         |\n",
      "|    explained_variance   | 0.0208        |\n",
      "|    learning_rate        | 0.0001        |\n",
      "|    loss                 | 624           |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.00157      |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 1.14e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 138          |\n",
      "|    ep_rew_mean          | -238         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 364          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 28           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041371374 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | -0.0163      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 428          |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00442     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 1.01e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 132           |\n",
      "|    ep_rew_mean          | -227          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 370           |\n",
      "|    iterations           | 6             |\n",
      "|    time_elapsed         | 33            |\n",
      "|    total_timesteps      | 12288         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00041411043 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.84         |\n",
      "|    explained_variance   | -0.0359       |\n",
      "|    learning_rate        | 0.0001        |\n",
      "|    loss                 | 735           |\n",
      "|    n_updates            | 50            |\n",
      "|    policy_gradient_loss | -0.00131      |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 1.66e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 132          |\n",
      "|    ep_rew_mean          | -215         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 374          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 38           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013857279 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | -0.0129      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 634          |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00131     |\n",
      "|    std                  | 0.998        |\n",
      "|    value_loss           | 1.21e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 132          |\n",
      "|    ep_rew_mean          | -202         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 376          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 43           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043229517 |\n",
      "|    clip_fraction        | 0.0156       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | -0.02        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 455          |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00433     |\n",
      "|    std                  | 0.998        |\n",
      "|    value_loss           | 1.06e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 124          |\n",
      "|    ep_rew_mean          | -180         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 375          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 49           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036887464 |\n",
      "|    clip_fraction        | 0.00889      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | -0.0405      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 541          |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00384     |\n",
      "|    std                  | 0.997        |\n",
      "|    value_loss           | 828          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 119          |\n",
      "|    ep_rew_mean          | -167         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 375          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 54           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010788105 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | -0.0118      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 482          |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00142     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 652          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 115         |\n",
      "|    ep_rew_mean          | -149        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 374         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003916096 |\n",
      "|    clip_fraction        | 0.00771     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.84       |\n",
      "|    explained_variance   | -0.00706    |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 475         |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00379    |\n",
      "|    std                  | 0.998       |\n",
      "|    value_loss           | 815         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 111         |\n",
      "|    ep_rew_mean          | -139        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 374         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 65          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004649354 |\n",
      "|    clip_fraction        | 0.0244      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.83       |\n",
      "|    explained_variance   | -0.00191    |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 308         |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00426    |\n",
      "|    std                  | 0.996       |\n",
      "|    value_loss           | 638         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 108          |\n",
      "|    ep_rew_mean          | -121         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 373          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 71           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029299678 |\n",
      "|    clip_fraction        | 0.00425      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | -0.00856     |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 251          |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00388     |\n",
      "|    std                  | 0.993        |\n",
      "|    value_loss           | 894          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 110          |\n",
      "|    ep_rew_mean          | -117         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 373          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 76           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036405057 |\n",
      "|    clip_fraction        | 0.00688      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.82        |\n",
      "|    explained_variance   | -0.00936     |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 192          |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00419     |\n",
      "|    std                  | 0.99         |\n",
      "|    value_loss           | 484          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 114         |\n",
      "|    ep_rew_mean          | -118        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 372         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 82          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005733262 |\n",
      "|    clip_fraction        | 0.0485      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.82       |\n",
      "|    explained_variance   | -0.00348    |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 292         |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00609    |\n",
      "|    std                  | 0.992       |\n",
      "|    value_loss           | 498         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 121          |\n",
      "|    ep_rew_mean          | -104         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 371          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 88           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025548907 |\n",
      "|    clip_fraction        | 0.00181      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.82        |\n",
      "|    explained_variance   | -0.04        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 350          |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.00173     |\n",
      "|    std                  | 0.986        |\n",
      "|    value_loss           | 641          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 128          |\n",
      "|    ep_rew_mean          | -108         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 369          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 94           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066270772 |\n",
      "|    clip_fraction        | 0.0401       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.81        |\n",
      "|    explained_variance   | -0.00132     |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 282          |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00544     |\n",
      "|    std                  | 0.986        |\n",
      "|    value_loss           | 525          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 140          |\n",
      "|    ep_rew_mean          | -103         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 361          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 101          |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024094097 |\n",
      "|    clip_fraction        | 0.00195      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.81        |\n",
      "|    explained_variance   | -0.00114     |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 231          |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00276     |\n",
      "|    std                  | 0.986        |\n",
      "|    value_loss           | 483          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 151          |\n",
      "|    ep_rew_mean          | -94.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 360          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 108          |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029329679 |\n",
      "|    clip_fraction        | 0.00703      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.81        |\n",
      "|    explained_variance   | 0.0129       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 104          |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00403     |\n",
      "|    std                  | 0.986        |\n",
      "|    value_loss           | 261          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 157         |\n",
      "|    ep_rew_mean          | -85.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 359         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 113         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005895015 |\n",
      "|    clip_fraction        | 0.0575      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.82       |\n",
      "|    explained_variance   | -0.0117     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 149         |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 0.994       |\n",
      "|    value_loss           | 274         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 163          |\n",
      "|    ep_rew_mean          | -80.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 357          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 120          |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037498781 |\n",
      "|    clip_fraction        | 0.00439      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | -0.00522     |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 173          |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00254     |\n",
      "|    std                  | 0.994        |\n",
      "|    value_loss           | 375          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 177        |\n",
      "|    ep_rew_mean          | -80.5      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 352        |\n",
      "|    iterations           | 22         |\n",
      "|    time_elapsed         | 127        |\n",
      "|    total_timesteps      | 45056      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00403429 |\n",
      "|    clip_fraction        | 0.0271     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.82      |\n",
      "|    explained_variance   | 0.00644    |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 202        |\n",
      "|    n_updates            | 210        |\n",
      "|    policy_gradient_loss | -0.00372   |\n",
      "|    std                  | 0.991      |\n",
      "|    value_loss           | 338        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 196          |\n",
      "|    ep_rew_mean          | -78.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 341          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 137          |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032077543 |\n",
      "|    clip_fraction        | 0.00825      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.82        |\n",
      "|    explained_variance   | 0.0224       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 180          |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00401     |\n",
      "|    std                  | 0.99         |\n",
      "|    value_loss           | 344          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 204          |\n",
      "|    ep_rew_mean          | -73.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 338          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 145          |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023371624 |\n",
      "|    clip_fraction        | 0.0021       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.82        |\n",
      "|    explained_variance   | 0.0866       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 72.5         |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.00271     |\n",
      "|    std                  | 0.99         |\n",
      "|    value_loss           | 148          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 219          |\n",
      "|    ep_rew_mean          | -68.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 335          |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 152          |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012468456 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.82        |\n",
      "|    explained_variance   | -0.0264      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 114          |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.00247     |\n",
      "|    std                  | 0.99         |\n",
      "|    value_loss           | 280          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 237          |\n",
      "|    ep_rew_mean          | -67.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 329          |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 161          |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027723103 |\n",
      "|    clip_fraction        | 0.00337      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.82        |\n",
      "|    explained_variance   | 0.06         |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 81.2         |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.00374     |\n",
      "|    std                  | 0.988        |\n",
      "|    value_loss           | 185          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 253          |\n",
      "|    ep_rew_mean          | -78.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 325          |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 169          |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038978658 |\n",
      "|    clip_fraction        | 0.0139       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.81        |\n",
      "|    explained_variance   | 0.125        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 104          |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.00299     |\n",
      "|    std                  | 0.985        |\n",
      "|    value_loss           | 176          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 268          |\n",
      "|    ep_rew_mean          | -74.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 321          |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 178          |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039250916 |\n",
      "|    clip_fraction        | 0.0151       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.81        |\n",
      "|    explained_variance   | 0.0546       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 160          |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.00614     |\n",
      "|    std                  | 0.984        |\n",
      "|    value_loss           | 375          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 284         |\n",
      "|    ep_rew_mean          | -73         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 187         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002164811 |\n",
      "|    clip_fraction        | 0.00254     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.8        |\n",
      "|    explained_variance   | 0.0462      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 95.5        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.00114    |\n",
      "|    std                  | 0.979       |\n",
      "|    value_loss           | 168         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 293          |\n",
      "|    ep_rew_mean          | -71.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 311          |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 196          |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036726668 |\n",
      "|    clip_fraction        | 0.0105       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.79        |\n",
      "|    explained_variance   | 0.21         |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 51.2         |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.00336     |\n",
      "|    std                  | 0.978        |\n",
      "|    value_loss           | 109          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 318         |\n",
      "|    ep_rew_mean          | -68.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 308         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 206         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003650139 |\n",
      "|    clip_fraction        | 0.0153      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.79       |\n",
      "|    explained_variance   | 0.372       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 28          |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.00332    |\n",
      "|    std                  | 0.976       |\n",
      "|    value_loss           | 77.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 331          |\n",
      "|    ep_rew_mean          | -79.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 307          |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 213          |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057570566 |\n",
      "|    clip_fraction        | 0.0462       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.78        |\n",
      "|    explained_variance   | 0.546        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 25           |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.00519     |\n",
      "|    std                  | 0.969        |\n",
      "|    value_loss           | 53.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 344          |\n",
      "|    ep_rew_mean          | -92.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 305          |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 220          |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044855047 |\n",
      "|    clip_fraction        | 0.0064       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.78        |\n",
      "|    explained_variance   | -0.0299      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 130          |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.0026      |\n",
      "|    std                  | 0.969        |\n",
      "|    value_loss           | 332          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 361         |\n",
      "|    ep_rew_mean          | -87.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 302         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 230         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005361246 |\n",
      "|    clip_fraction        | 0.0397      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.78       |\n",
      "|    explained_variance   | 0.273       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 193         |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00823    |\n",
      "|    std                  | 0.97        |\n",
      "|    value_loss           | 543         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 371          |\n",
      "|    ep_rew_mean          | -88.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 299          |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 239          |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037661386 |\n",
      "|    clip_fraction        | 0.0147       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.77        |\n",
      "|    explained_variance   | 0.352        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 66           |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.00513     |\n",
      "|    std                  | 0.965        |\n",
      "|    value_loss           | 89.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 386          |\n",
      "|    ep_rew_mean          | -84.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 297          |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 248          |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021181493 |\n",
      "|    clip_fraction        | 0.0022       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.77        |\n",
      "|    explained_variance   | 0.0634       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 62.3         |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.00213     |\n",
      "|    std                  | 0.965        |\n",
      "|    value_loss           | 168          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 405          |\n",
      "|    ep_rew_mean          | -89.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 294          |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 257          |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040031797 |\n",
      "|    clip_fraction        | 0.0189       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.77        |\n",
      "|    explained_variance   | 0.42         |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 42.6         |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.00271     |\n",
      "|    std                  | 0.966        |\n",
      "|    value_loss           | 98.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 409         |\n",
      "|    ep_rew_mean          | -92.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 293         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 265         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003104482 |\n",
      "|    clip_fraction        | 0.0151      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.77       |\n",
      "|    explained_variance   | 0.472       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 47.6        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.00339    |\n",
      "|    std                  | 0.964       |\n",
      "|    value_loss           | 139         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 429          |\n",
      "|    ep_rew_mean          | -90.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 292          |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 273          |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041618748 |\n",
      "|    clip_fraction        | 0.0215       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.76        |\n",
      "|    explained_variance   | 0.425        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 35.4         |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.00618     |\n",
      "|    std                  | 0.962        |\n",
      "|    value_loss           | 77.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 444          |\n",
      "|    ep_rew_mean          | -93.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 289          |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 283          |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050624884 |\n",
      "|    clip_fraction        | 0.0254       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.76        |\n",
      "|    explained_variance   | 0.359        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 60.1         |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.00444     |\n",
      "|    std                  | 0.957        |\n",
      "|    value_loss           | 90.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 460          |\n",
      "|    ep_rew_mean          | -92.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 287          |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 291          |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058113346 |\n",
      "|    clip_fraction        | 0.0364       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.75        |\n",
      "|    explained_variance   | 0.34         |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 23.5         |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -0.00538     |\n",
      "|    std                  | 0.959        |\n",
      "|    value_loss           | 76.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 472          |\n",
      "|    ep_rew_mean          | -92          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 286          |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 300          |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038271444 |\n",
      "|    clip_fraction        | 0.00928      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.76        |\n",
      "|    explained_variance   | 0.0685       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 60.4         |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.00351     |\n",
      "|    std                  | 0.961        |\n",
      "|    value_loss           | 161          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 488         |\n",
      "|    ep_rew_mean          | -92.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 309         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004861744 |\n",
      "|    clip_fraction        | 0.018       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.76       |\n",
      "|    explained_variance   | 0.358       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 27.5        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0034     |\n",
      "|    std                  | 0.959       |\n",
      "|    value_loss           | 93.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 511         |\n",
      "|    ep_rew_mean          | -94.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 318         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009405039 |\n",
      "|    clip_fraction        | 0.0768      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.75       |\n",
      "|    explained_variance   | 0.37        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 23.1        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    std                  | 0.961       |\n",
      "|    value_loss           | 55.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 527          |\n",
      "|    ep_rew_mean          | -96.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 282          |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 326          |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049728444 |\n",
      "|    clip_fraction        | 0.022        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.76        |\n",
      "|    explained_variance   | 0.484        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 26.4         |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.00587     |\n",
      "|    std                  | 0.961        |\n",
      "|    value_loss           | 93.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 544         |\n",
      "|    ep_rew_mean          | -97.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 280         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 335         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006403164 |\n",
      "|    clip_fraction        | 0.0666      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.76       |\n",
      "|    explained_variance   | 0.547       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 19.8        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    std                  | 0.962       |\n",
      "|    value_loss           | 36.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 563          |\n",
      "|    ep_rew_mean          | -97.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 278          |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 345          |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066400464 |\n",
      "|    clip_fraction        | 0.0513       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.76        |\n",
      "|    explained_variance   | 0.591        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 13.1         |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.00647     |\n",
      "|    std                  | 0.962        |\n",
      "|    value_loss           | 30           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 579          |\n",
      "|    ep_rew_mean          | -95.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 276          |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 354          |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037292028 |\n",
      "|    clip_fraction        | 0.0163       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.76        |\n",
      "|    explained_variance   | 0.745        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 8.49         |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.00328     |\n",
      "|    std                  | 0.963        |\n",
      "|    value_loss           | 19.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 597         |\n",
      "|    ep_rew_mean          | -95.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 276         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 363         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002585518 |\n",
      "|    clip_fraction        | 0.00942     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.76       |\n",
      "|    explained_variance   | 0.632       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 11.4        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0029     |\n",
      "|    std                  | 0.964       |\n",
      "|    value_loss           | 35.5        |\n",
      "-----------------------------------------\n",
      "Recompensa media: -51.512971500000006\n",
      "Desviaci贸n est谩ndar de la recompensa: 55.73676648371249\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import imageio\n",
    "import numpy as np\n",
    "\n",
    "env = make_vec_env(lambda: gym.make(\"LunarLander-v2\", render_mode=\"rgb_array\", continuous=True), n_envs=1)\n",
    "\n",
    "learning_rate = 0.0001\n",
    "batch_size = 128\n",
    "total_timesteps = 100000\n",
    "\n",
    "model = PPO(\"MlpPolicy\", env, learning_rate=learning_rate, batch_size=batch_size, verbose=1)\n",
    "model.learn(total_timesteps=total_timesteps)\n",
    "\n",
    "model.save(\"ppo_lunarlander_model_optimized\")\n",
    "\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=10)\n",
    "\n",
    "print(f\"Recompensa media: {mean_reward}\")\n",
    "print(f\"Desviaci贸n est谩ndar de la recompensa: {std_reward}\")\n",
    "\n",
    "export_gif(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Descripci贸n del GIF](./agent_performance_optimized.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El performance del agente entrenado utilizando el modelo PPO es significativamente mejor que el escenario baseline de acciones aleatorias. Esto se refleja en la recompensa media obtenida, que es de -51.51, con una desviaci贸n est谩ndar de 55.74.\n",
    "\n",
    "### Comparaci贸n con el Baseline\n",
    "\n",
    "- **Promedio de Recompensas**: El promedio de recompensas del agente entrenado es mucho mejor que el promedio negativo del baseline (-149.31). Esto indica que el agente entrenado tiene un mejor desempe帽o general.\n",
    "- **Desviaci贸n Est谩ndar**: La desviaci贸n est谩ndar de las recompensas del agente entrenado es mayor que la del baseline (55.74 vs. 91.36). Esto sugiere que hay una mayor variabilidad en las recompensas obtenidas, lo cual es esperable dado que el agente est谩 tomando decisiones m谩s informadas y, por lo tanto, puede obtener mejores recompensas en algunos episodios.\n",
    "\n",
    "En resumen, el agente entrenado con PPO muestra un mejor performance en comparaci贸n con la pol铆tica de acciones aleatorias, lo que demuestra la efectividad del modelo de RL en aprender una estrategia para el ambiente de LunarLander.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mPUY-Ktgf2BO"
   },
   "source": [
    "## **2. Large Language Models (4.0 puntos)**\n",
    "\n",
    "En esta secci贸n se enfocar谩n en habilitar un Chatbot que nos permita responder preguntas 煤tiles a trav茅s de LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQ4fPRRihGLe"
   },
   "source": [
    "### **2.0 Configuraci贸n Inicial**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://media1.tenor.com/m/uqAs9atZH58AAAAd/config-config-issue.gif\"\n",
    "\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "Como siempre, cargamos todas nuestras API KEY al entorno:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ud2Xm_k-hFJn"
   },
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google AI API key: \")\n",
    "\n",
    "if \"TAVILY_API_KEY\" not in os.environ:\n",
    "    os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Enter your Tavily API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rj9JvQUsgZZJ"
   },
   "source": [
    "### **2.1 Retrieval Augmented Generation (1.5 puntos)**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://y.yarn.co/218aaa02-c47e-4ec9-b1c9-07792a06a88f_text.gif\"\n",
    "\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "El objetivo de esta subsecci贸n es que habiliten un chatbot que pueda responder preguntas usando informaci贸n contenida en documentos PDF a trav茅s de **Retrieval Augmented Generation.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZrxOQroVnaZ5"
   },
   "source": [
    "#### **2.1.1 Reunir Documentos (0 puntos)**\n",
    "\n",
    "Reuna documentos PDF sobre los que hacer preguntas siguiendo las siguientes instrucciones:\n",
    "  - 2 documentos .pdf como m铆nimo.\n",
    "  - 50 p谩ginas de contenido como m铆nimo entre todos los documentos.\n",
    "  - Ideas para documentos: Documentos relacionados a temas acad茅micos, laborales o de ocio. Aprovechen este ejercicio para construir algo 煤til y/o relevante para ustedes!\n",
    "  - Deben ocupar documentos reales, no pueden utilizar los mismos de la clase.\n",
    "  - Deben registrar sus documentos en la siguiente [planilla](https://docs.google.com/spreadsheets/d/1Hy1w_dOiG2UCHJ8muyxhdKPZEPrrL7BNHm6E90imIIM/edit?usp=sharing). **NO PUEDEN USAR LOS MISMOS DOCUMENTOS QUE OTRO GRUPO**\n",
    "  - **Recuerden adjuntar los documentos en su entrega**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5D1tIRCi4oJJ",
    "outputId": "39f6d4fc-63cb-4b9b-d48f-48d60df25ee5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m225.3/232.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kzq2TjWCnu15"
   },
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "\n",
    "doc_paths = [] # rellenar con los path a sus documentos\n",
    "\n",
    "assert len(doc_paths) >= 2, \"Deben adjuntar un m铆nimo de 2 documentos\"\n",
    "\n",
    "total_paginas = sum(len(PyPDF2.PdfReader(open(doc, \"rb\")).pages) for doc in doc_paths)\n",
    "assert total_paginas >= 50, f\"P谩ginas insuficientes: {total_paginas}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r811-P71nizA"
   },
   "source": [
    "#### **2.1.2 Vectorizar Documentos (0.2 puntos)**\n",
    "\n",
    "Vectorice los documentos y almacene sus representaciones de manera acorde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n-yXAdCSn4JM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hAUkP5zrnyBK"
   },
   "source": [
    "#### **2.1.3 Habilitar RAG (0.3 puntos)**\n",
    "\n",
    "Habilite la soluci贸n RAG a trav茅s de una *chain* y gu谩rdela en una variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gPIySdDFn99l"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ycg5S5i_n-kL"
   },
   "source": [
    "#### **2.1.4 Verificaci贸n de respuestas (0.5 puntos)**\n",
    "\n",
    "Genere un listado de 3 tuplas (\"pregunta\", \"respuesta correcta\") y analice la respuesta de su soluci贸n para cada una. 驴Su soluci贸n RAG entrega las respuestas que esperaba?\n",
    "\n",
    "Ejemplo de tupla:\n",
    "- Pregunta: 驴Qui茅n es el presidente de Chile?\n",
    "- Respuesta correcta: El presidente de Chile es Gabriel Boric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S_UiEn1hoZYR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8d5zTMHoUgF"
   },
   "source": [
    "#### **2.1.5 Sensibilidad de Hiperpar谩metros (0.5 puntos)**\n",
    "\n",
    "Extienda el an谩lisis del punto 2.1.4 analizando c贸mo cambian las respuestas entregadas cambiando los siguientes hiperpar谩metros:\n",
    "- `Tama帽o del chunk`. (*驴C贸mo repercute que los chunks sean mas grandes o chicos?*)\n",
    "- `La cantidad de chunks recuperados`. (*驴Qu茅 pasa si se devuelven muchos/pocos chunks?*)\n",
    "- `El tipo de b煤squeda`. (*驴C贸mo afecta el tipo de b煤squeda a las respuestas de mi RAG?*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UDh_QgeXLGHc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ENJiPPM0giX8"
   },
   "source": [
    "### **2.2 Agentes (1.0 puntos)**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://media1.tenor.com/m/rcqnN2aJCSEAAAAd/secret-agent-man.gif\"\n",
    "\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "Similar a la secci贸n anterior, en esta secci贸n se busca habilitar **Agentes** para obtener informaci贸n a trav茅s de tools y as铆 responder la pregunta del usuario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V47l7Mjfrk0N"
   },
   "source": [
    "#### **2.2.1 Tool de Tavily (0.2 puntos)**\n",
    "\n",
    "Generar una *tool* que pueda hacer consultas al motor de b煤squeda **Tavily**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R6SLKwcWr0AG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SonB1A-9rtRq"
   },
   "source": [
    "#### **2.2.2 Tool de Wikipedia (0.2 puntos)**\n",
    "\n",
    "Generar una *tool* que pueda hacer consultas a **Wikipedia**.\n",
    "\n",
    "*Hint: Le puede ser de ayuda el siguiente [link](https://python.langchain.com/v0.1/docs/modules/tools/).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ehJJpoqsr26-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CvUIMdX6r0ne"
   },
   "source": [
    "#### **2.2.3 Crear Agente (0.3 puntos)**\n",
    "\n",
    "Crear un agente que pueda responder preguntas preguntas usando las *tools* antes generadas. Aseg煤rese que su agente responda en espa帽ol. Por 煤ltimo, guarde el agente en una variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pD1_n0wrsDI5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dKV0JxK3r-XG"
   },
   "source": [
    "#### **2.2.4 Verificaci贸n de respuestas (0.3 puntos)**\n",
    "\n",
    "Pruebe el funcionamiento de su agente y aseg煤rese que el agente est茅 ocupando correctamente las tools disponibles. 驴En qu茅 casos el agente deber铆a ocupar la tool de Tavily? 驴En qu茅 casos deber铆a ocupar la tool de Wikipedia?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pqo2dsxvywW_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cZbDTYiogquv"
   },
   "source": [
    "### **2.3 Multi Agente (1.5 puntos)**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://media1.tenor.com/m/r7QMJLxU4BoAAAAd/this-is-getting-out-of-hand-star-wars.gif\"\n",
    "\" width=\"450\">\n",
    "</p>\n",
    "\n",
    "El objetivo de esta subsecci贸n es encapsular las funcionalidades creadas en una soluci贸n multiagente con un **supervisor**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7-iUfH0WvI6m"
   },
   "source": [
    "#### **2.3.1 Generando Tools (0.5 puntos)**\n",
    "\n",
    "Transforme la soluci贸n RAG de la secci贸n 2.1 y el agente de la secci贸n 2.2 a *tools* (una tool por cada uno)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pw1cfTtvv1AZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HQYNjT_0vPCg"
   },
   "source": [
    "#### **2.3.2 Agente Supervisor (0.5 puntos)**\n",
    "\n",
    "Habilite un agente que tenga acceso a las tools del punto anterior y pueda responder preguntas relacionadas. Almacene este agente en una variable llamada supervisor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yv2ZY0BAv1RD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ea3zWlvyvY7K"
   },
   "source": [
    "#### **2.3.3 Verificaci贸n de respuestas (0.25 puntos)**\n",
    "\n",
    "Pruebe el funcionamiento de su agente repitiendo las preguntas realizadas en las secciones 2.1.4 y 2.2.4 y comente sus resultados. 驴C贸mo var铆an las respuestas bajo este enfoque?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6_1t0zkgv1qW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qb8bdAmYvgwn"
   },
   "source": [
    "#### **2.3.4 An谩lisis (0.25 puntos)**\n",
    "\n",
    "驴Qu茅 diferencias tiene este enfoque con la soluci贸n *Router* vista en clases? Nombre al menos una ventaja y desventaja."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YAUlJxqoLK5r"
   },
   "source": [
    "`escriba su respuesta ac谩`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4JWVSuWiZ8Mj"
   },
   "source": [
    "### **2.4 Memoria (Bonus +0.5 puntos)**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://media1.tenor.com/m/Gs95aiElrscAAAAd/memory-unlocked-ratatouille-critic.gif\"\n",
    "\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "Una de las principales falencias de las soluciones que hemos visto hasta ahora es que nuestro chat no responde las interacciones anteriores, por ejemplo:\n",
    "\n",
    "- Pregunta 1: \"Hola! mi nombre es Sebasti谩n\"\n",
    "  - Respuesta esperada: \"Hola Sebasti谩n! ...\"\n",
    "- Pregunta 2: \"Cual es mi nombre?\"\n",
    "  - Respuesta actual: \"Lo siento pero no conozco tu nombre :(\"\n",
    "  - **Respuesta esperada: \"Tu nombre es Sebasti谩n\"**\n",
    "\n",
    "Para solucionar esto, se les solicita agregar un componente de **memoria** a la soluci贸n entregada en el punto 2.3.\n",
    "\n",
    "**Nota: El Bonus es v谩lido <u>s贸lo para la secci贸n 2 de Large Language Models.</u>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K6Y7tIPJLPfB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vFc3jBT5g0kT"
   },
   "source": [
    "### **2.5 Despliegue (0 puntos)**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://media1.tenor.com/m/IytHqOp52EsAAAAd/you-get-a-deploy-deploy.gif\"\n",
    "\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "Una vez tengan los puntos anteriores finalizados, toca la etapa de dar a conocer lo que hicimos! Para eso, vamos a desplegar nuestro modelo a trav茅s de `gradio`, una librer铆a especializada en el levantamiento r谩pido de demos basadas en ML.\n",
    "\n",
    "Primero instalamos la librer铆a:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T8TsvnCPbkIA"
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HJBztEUovKsF"
   },
   "source": [
    "Luego s贸lo deben ejecutar el siguiente c贸digo e interactuar con la interfaz a trav茅s del notebook o del link generado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z3KedQSvg1-n"
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import time\n",
    "\n",
    "def agent_response(message, history):\n",
    "  '''\n",
    "  Funci贸n para gradio, recibe mensaje e historial, devuelte la respuesta del chatbot.\n",
    "  '''\n",
    "  # get chatbot response\n",
    "  response = ... # rellenar con la respuesta de su chat\n",
    "\n",
    "  # assert\n",
    "  assert type(response) == str, \"output de route_question debe ser string\"\n",
    "\n",
    "  # \"streaming\" response\n",
    "  for i in range(len(response)):\n",
    "    time.sleep(0.015)\n",
    "    yield response[: i+1]\n",
    "\n",
    "gr.ChatInterface(\n",
    "    agent_response,\n",
    "    type=\"messages\",\n",
    "    title=\"Chatbot MDS7202\", # Pueden cambiar esto si lo desean\n",
    "    description=\"Hola! Soy un chatbot muy 煤til :)\", # tambi茅n la descripci贸n\n",
    "    theme=\"soft\",\n",
    "    ).launch(\n",
    "        share=True, # pueden compartir el link a sus amig@s para que interactuen con su chat!\n",
    "        debug = False,\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
